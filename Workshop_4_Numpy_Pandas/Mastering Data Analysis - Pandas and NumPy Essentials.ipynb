{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72321cd",
   "metadata": {},
   "source": [
    "## NumPy: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7eab6",
   "metadata": {},
   "source": [
    "### Setting up NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63042644",
   "metadata": {},
   "source": [
    "`import numpy`: This tells Python to load the NumPy library, making its functions and classes available in the script.\n",
    "\n",
    "`as np`: This renames the namespace to np. It's a mechanism that allows you to refer to numpy with the shorter np prefix, reducing the amount of typing required for namespace specification and improving code readability.\n",
    "\n",
    "The sole reason that numpy is imported as np is convention. You are free to use another alias but it's not recommended as this is what you will find everywhere and it's better to stick to standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5082ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1a6aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a435a",
   "metadata": {},
   "source": [
    "### Moving from lists to array: \n",
    "\n",
    "* Think of an array as a row of mailboxes at an apartment building. Each mailbox is the same size and holds mail (data) for each apartment (element in the array). You can easily find who the mail belongs to because the mailboxes are numbered in order. But, every mailbox has to hold the same kind of thing, like only letters or only packages, not both.\n",
    "\n",
    "* A list in Python is like a big bag where you can put anything you want – letters, packages, a basketball – and you can keep adding more things or take some out. It's super flexible, but if you're trying to find something specific, it might take longer to dig around because there's all sorts of stuff in there.\n",
    "\n",
    "* So, while an array is like a neatly organized row of same-sized mailboxes, a list is more like a big, mixed bag of goodies. They both hold stuff, but an array is more about being tidy and quick to find things when they're all the same type, and a list is about being able to hold anything you want, anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a265f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 μs ± 154 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "1.78 μs ± 108 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pythonList = [i for i in range(10000)]\n",
    "%timeit npList = np.arange(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee976761",
   "metadata": {},
   "source": [
    "Python lists are versatile, allowing for a mix of different data types and can adjust in size. However, this flexibility can slow them down for number-heavy tasks. NumPy arrays, on the other hand, require all elements to be the same type, which makes them more efficient for storage and faster for calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26576ffb",
   "metadata": {},
   "source": [
    "### nd-array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a3529e",
   "metadata": {},
   "source": [
    "\n",
    "* The primary reason that numpy is fast is because of the nd-array type that it uses to store and manipulate data.\n",
    "\n",
    "* An ndarray is a generic multidimensional container for homogenous data. It provides arithmetic operations and broadcasting capabilities. \n",
    "\n",
    "* Every ndarray has 2 properties: shape and dtype. shape is a tuple providing the dimension of the array and dtype provides you the datatype of the array.\n",
    "\n",
    "* The dtype of the array can also be explicitly specified while defining the array giving you fine-tuned control over the array.\n",
    "\n",
    "Let's create a numpy array from an array. This is possible by passing the array as input to the np.array function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca4951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an integer array.\n",
    "nparray = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266adec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302ad9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatype of the array.\n",
    "nparray.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4eb88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an integer array with explicit dtype, which is not necessary.\n",
    "int_array = np.array([1, 2, 3], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab7a66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e9cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an 2D array\n",
    "original_array = np.array([[1, 2, 3],\n",
    "                           [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7426631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6002586",
   "metadata": {},
   "source": [
    "### Array Dimension and Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29e5d1",
   "metadata": {},
   "source": [
    "* A one-dimensional array is like a list/vector, a two-dimensional array is akin to a matrix, and so on. Get dimension using array_name.ndim\n",
    "\n",
    "* Array shape specifies the number of elements along each dimension. It is represented as a tuple of integers. Array size is basically the product of a number of rows and columns. You can get them by using array_name.shape and array_name.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eaf3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension (1D): 1, Shape: (3,), size: 3\n",
      "Dimension (2D): 2, Shape: (2, 3), size: 6\n"
     ]
    }
   ],
   "source": [
    "# Creating a 1D array (Vector)\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "# Dimesion: 1 , Shape: (3,), Size: 3\n",
    "print(f\"Dimension (1D): {arr_1d.ndim}, Shape: {arr_1d.shape}, size: {arr_1d.size}\")\n",
    "\n",
    "# Creating a 2D array (Matrix) # Dimension: 2 , Shape: (2, 3)\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]]) \n",
    "print(f\"Dimension (2D): {arr_2d.ndim}, Shape: {arr_2d.shape}, size: {arr_2d.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d15ad2",
   "metadata": {},
   "source": [
    "### Creating NumPy Arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c41a07",
   "metadata": {},
   "source": [
    "#### arange\n",
    "\n",
    "* arange generates an array of numbers within the range of the digit that's passed.\n",
    "\n",
    "* It created an array with regularly spaced values between start and stop with a specified step size.\n",
    "`np.arange(start, stop, step, dtype=None).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf6aff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00264193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array of values from 0 to 9 with a step size of 2\n",
    "np.arange(0, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a943ad",
   "metadata": {},
   "source": [
    "#### linspace\n",
    "\n",
    "* linspace returns a set of linearly-spaced items within the range passed as input. \n",
    "* In linspace, the starting digit, ending digit along with the number of digits required as passed as input. \n",
    "* Basically, it returns an array with the required number of digits in a specified interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f364329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array of 10 equally spaced values from 0 to 1\n",
    "np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3d186d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  2.5,  5. ,  7.5, 10. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808f354",
   "metadata": {},
   "source": [
    "#### zeros and ones\n",
    "\n",
    "* zeros creates an array filled with zeroes. The parameter passed as input is the size of the required array.\n",
    "* ones creates an array filled with ones. The parameter passed as input is the size of the required array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b20f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c318bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3x3 array filled with zeros\n",
    "np.zeros((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf59dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b1b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x4 array filled with ones\n",
    "np.ones((2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab3234",
   "metadata": {},
   "source": [
    "#### np.zeros_like: creates a new array filled with zeros but with the same shape and data type as an existing array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30754d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8731e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new array filled with zeros, \n",
    "# matching the shape and data type of the original array\n",
    "zeros_array = np.zeros_like(original_array)\n",
    "zeros_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b4c50",
   "metadata": {},
   "source": [
    "#### np.ones_like: is similar to np.zeros_like, but it creates a new array filled with ones instead of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e091019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones_like(np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b681c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new array filled with ones, \n",
    "# matching the shape and data type of the original array\n",
    "ones_array = np.ones_like(original_array)\n",
    "ones_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5dc7d",
   "metadata": {},
   "source": [
    "### Array Indexing and Slicing\n",
    "\n",
    "* Array Indexing: Refers to accessing individual elements within a NumPy array.\n",
    "\n",
    "* Array Slicing: This allows you to extract specific portions of an array, creating new arrays with the selected elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29c60fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [10 20 30 40 50]\n",
      "First element: 10\n",
      "Last element: 50\n",
      "\n",
      "Original 2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Element at row 0, column 1: 2\n"
     ]
    }
   ],
   "source": [
    "# Creating a NumPy array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original array:\", arr)\n",
    "\n",
    "# Accessing individual elements\n",
    "first_element = arr[0]  # Access the first element\n",
    "print(\"First element:\", first_element)\n",
    "\n",
    "# Accessing elements using negative indices\n",
    "last_element = arr[-1]  # Access the last element\n",
    "print(\"Last element:\", last_element)\n",
    "\n",
    "# Creating a 2D NumPy array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\nOriginal 2D array:\\n\", arr_2d)\n",
    "\n",
    "# Accessing an individual element in 2D array\n",
    "element_row_0_col_1 = arr_2d[0, 1]  # Element at row 0, column 1\n",
    "print(\"Element at row 0, column 1:\", element_row_0_col_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5825c202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [10 20 30 40 50]\n",
      "Sliced array from index 1 to 3: [20 30 40]\n",
      "Array with elements at every 2nd position: [10 30 50]\n",
      "Last two elements of the array: [40 50]\n",
      "Elements greater than 30: [40 50]\n",
      "\n",
      "Original 2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "2x2 subarray from the 2D array:\n",
      " [[4 5]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a 1D NumPy array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original array:\", arr)\n",
    "\n",
    "# Slicing the array to create a new array\n",
    "sliced_array = arr[1:4]  # Slice from index 1 to 3 (exclusive)\n",
    "print(\"Sliced array from index 1 to 3:\", sliced_array)\n",
    "\n",
    "# Slicing with a step of 2\n",
    "sliced_array = arr[0::2]  # Start at index 0, step by 2\n",
    "print(\"Array with elements at every 2nd position:\", sliced_array)\n",
    "\n",
    "# Slicing with negative index\n",
    "second_to_last = arr[-2::]  # Access the last two elements\n",
    "print(\"Last two elements of the array:\", second_to_last)\n",
    "\n",
    "# Conditional slicing: Select elements greater than 30\n",
    "sliced_array = arr[arr > 30]  # Result: [40, 50]\n",
    "print(\"Elements greater than 30:\", sliced_array)\n",
    "\n",
    "# Creating a 2D NumPy array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\nOriginal 2D array:\\n\", arr_2d)\n",
    "\n",
    "# Slicing along rows and columns\n",
    "sliced_array = arr_2d[1:3, 0:2] # Slice a 2x2 subarray\n",
    "print(\"2x2 subarray from the 2D array:\\n\", sliced_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e3f29",
   "metadata": {},
   "source": [
    "### Array Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9892b17",
   "metadata": {},
   "source": [
    "#### Element-wise Operations\n",
    "\n",
    "Element-wise operations apply a given operation to each element in the array independently. You can perform addition, subtraction, even multiplication, and division as well on the arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7ceb9",
   "metadata": {},
   "source": [
    "#### 1. Broadcasting: \n",
    "    \n",
    "NumPy allows operations between arrays of different shapes and sizes which is called broadcasting. Broadcasting automatically adjusts the smaller array’s shape to match the larger array, making it compatible with element-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e66041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition of arr1 and arr2: [5 7 9]\n",
      "Element-wise multiplication of arr1 and arr2: [ 4 10 18]\n",
      "Subtraction of arr2 from arr1: [-3 -3 -3]\n",
      "Division of arr1 by arr2: [0.25 0.4  0.5 ]\n",
      "Element-wise multiplication of matrix1 and matrix2:\n",
      " [[ 5 12]\n",
      " [21 32]]\n",
      "Matrix multiplication of matrix1 and matrix2 using np.dot:\n",
      " [[19 22]\n",
      " [43 50]]\n",
      "Multiplying arr1 by a scalar (2): [2 4 6]\n"
     ]
    }
   ],
   "source": [
    "# Creating 1D NumPy arrays\n",
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "scalar = 2\n",
    "\n",
    "# Addition\n",
    "result_add = arr1 + arr2\n",
    "print(\"Addition of arr1 and arr2:\", result_add)  # Output: [5, 7, 9]\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "result_mul = arr1 * arr2\n",
    "print(\"Element-wise multiplication of arr1 and arr2:\", result_mul)  # Output: [4, 10, 18]\n",
    "\n",
    "# Subtraction\n",
    "result_sub = arr1 - arr2\n",
    "print(\"Subtraction of arr2 from arr1:\", result_sub)  # Output: [-3, -3, -3]\n",
    "\n",
    "# Division\n",
    "result_div = arr1 / arr2\n",
    "print(\"Division of arr1 by arr2:\", result_div)  # Output: [0.25, 0.4, 0.5]\n",
    "\n",
    "# Creating 2D NumPy arrays\n",
    "matrix1 = np.array([[1, 2], [3, 4]])\n",
    "matrix2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Element-wise multiplication (NOT matrix multiplication)\n",
    "result_mul_2d = matrix1 * matrix2\n",
    "print(\"Element-wise multiplication of matrix1 and matrix2:\\n\", result_mul_2d)\n",
    "\n",
    "# Actual Matrix Multiplication using np.dot\n",
    "matrix_multiplication = np.dot(matrix1, matrix2)\n",
    "print(\"Matrix multiplication of matrix1 and matrix2 using np.dot:\\n\", matrix_multiplication)\n",
    "\n",
    "# Broadcasting: Multiply array by a scalar\n",
    "result_broadcast = arr1 * scalar\n",
    "print(\"Multiplying arr1 by a scalar (2):\", result_broadcast)  # Output: [2, 4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a529f1",
   "metadata": {},
   "source": [
    "#### Append and Delete\n",
    "\n",
    "* To append arrays in NumPy, you can use the numpy.append() function. This function allows you to add elements to the end of an existing array along a specified axis.\n",
    "\n",
    "* Keep in mind that np.append() returns a new array with the appended elements; so it does not modify the original arrays. If you want to modify an existing array in-place, you can use methods like np.concatenate() or use assignment statements.\n",
    "\n",
    "* We can use np.delete to remove the items from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da9c4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [1 2 3]\n",
      "Array after appending [4, 5, 6]: [1 2 3 4 5 6]\n",
      "\n",
      "New array for deletion operations: [1 2 3 4 5]\n",
      "Array after removing element at index 2: [1 2 4 5]\n",
      "\n",
      "Original 2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "2D array after removing second row:\n",
      " [[1 2 3]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Create an array\n",
    "original_array = np.array([1, 2, 3])\n",
    "print(\"Original array:\", original_array)\n",
    "\n",
    "# Append elements in-place\n",
    "original_array = np.append(original_array, [4, 5, 6])\n",
    "print(\"Array after appending [4, 5, 6]:\", original_array)\n",
    "\n",
    "# Create a NumPy array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"\\nNew array for deletion operations:\", arr)\n",
    "\n",
    "# Remove the item at index 2 (value 3)\n",
    "new_arr = np.delete(arr, 2)\n",
    "print(\"Array after removing element at index 2:\", new_arr)\n",
    "\n",
    "# Create a 2D NumPy array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\nOriginal 2D array:\\n\", arr_2d)\n",
    "\n",
    "# Remove the second row (index 1)\n",
    "new_arr_2d = np.delete(arr_2d, 1, axis=0)\n",
    "print(\"2D array after removing second row:\\n\", new_arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8abc8",
   "metadata": {},
   "source": [
    "#### Aggregation Functions and ufuncs\n",
    "\n",
    "NumPy provides built-in functions for common aggregation operations on arrays, including mean, sum, minimum, maximum, etc. NumPy also provides universal functions (ufuncs) that operate element-wise on arrays, including mathematical, trigonometric, and exponential functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "952c291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [1 2 3 4 5]\n",
      "Mean value: 3.0\n",
      "Median value: 3.0\n",
      "Variance: 2.0\n",
      "Standard deviation: 1.4142135623730951\n",
      "Sum of all elements: 15\n",
      "Minimum value: 1\n",
      "Maximum value: 5\n",
      "\n",
      "Square root of each element: [1.         1.41421356 1.73205081 2.         2.23606798]\n",
      "Exponential of each element: [  2.71828183   7.3890561   20.08553692  54.59815003 148.4131591 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a NumPy array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Original array:\", arr)\n",
    "\n",
    "# Aggregation functions\n",
    "mean_value = np.mean(arr)\n",
    "print(\"Mean value:\", mean_value)\n",
    "\n",
    "median_value = np.median(arr)\n",
    "print(\"Median value:\", median_value)\n",
    "\n",
    "variance = np.var(arr)\n",
    "print(\"Variance:\", variance)\n",
    "\n",
    "standard_deviation = np.std(arr)\n",
    "print(\"Standard deviation:\", standard_deviation)\n",
    "\n",
    "sum_value = np.sum(arr)\n",
    "print(\"Sum of all elements:\", sum_value)\n",
    "\n",
    "min_value = np.min(arr)\n",
    "print(\"Minimum value:\", min_value)\n",
    "\n",
    "max_value = np.max(arr)\n",
    "print(\"Maximum value:\", max_value)\n",
    "\n",
    "# Universal functions\n",
    "sqrt_arr = np.sqrt(arr)\n",
    "print(\"\\nSquare root of each element:\", sqrt_arr)\n",
    "\n",
    "exp_arr = np.exp(arr)\n",
    "print(\"Exponential of each element:\", exp_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f6dcf",
   "metadata": {},
   "source": [
    "#### Reshpaing Arrays\n",
    "\n",
    "* You can change the shape of an array without changing its data using the reshape method, say to flatten an array (convert it to a 1D array) or to change it to a higher-dimensional array (e.g., from 1D to 2D or 2D to 3D).\n",
    "\n",
    "* The reshape method can be particularly useful when you need to prepare data for various operations, such as matrix multiplication, convolution, or displaying images.\n",
    "\n",
    "* To reshape method, you can pass the shape of the expected result you want it to be. The total number of elements in the original array must match the total number of elements in the new shape. In other words, the product of the dimensions in the new shape should be equal to the total number of elements in the original array. NumPy will raise an error if this condition is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2095ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Converted to 1D array: [1 2 3 4 5 6]\n",
      "\n",
      "Original 1D array: [1 2 3 4 5 6]\n",
      "\n",
      "Reshaped back to 2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a 2D array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original 2D array:\\n\", arr_2d)\n",
    "\n",
    "# Reshaping the 2D array to a 1D array\n",
    "arr_1d = arr_2d.reshape(6)\n",
    "print(\"\\nConverted to 1D array:\", arr_1d)\n",
    "\n",
    "# Creating a 1D array\n",
    "arr_1d = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"\\nOriginal 1D array:\", arr_1d)\n",
    "\n",
    "# Reshaping the 1D array back to a 2D array\n",
    "arr_2d = arr_1d.reshape(2, 3)\n",
    "print(\"\\nReshaped back to 2D array:\\n\", arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513989b",
   "metadata": {},
   "source": [
    "#### Combining Arrays\n",
    "\n",
    "NumPy provides the np.concatenate() function to concatenate arrays along a specified axis. And Stacking arrays can be done using functions like np.vstack() (vertical stacking) and np.hstack() (horizontal stacking).\n",
    "\n",
    "* Concatenation directly joins two arrays end-to-end.\n",
    "* Vertical stacking places one array on top of the other, creating a 2D array if starting with 1D arrays.\n",
    "* Horizontal stacking places arrays side by side, similar to concatenation for 1D arrays but is also applicable for 2D arrays to combine them column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876a2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated array: [1 2 3 4 5 6]\n",
      "Vertically stacked:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "Horizontally stacked: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "\n",
    "# Concatenate along the 0-axis (rows)\n",
    "combined = np.concatenate((arr1, arr2))\n",
    "print(\"Concatenated array:\", combined)  # Result: [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Vertical stacking\n",
    "vertical_stack = np.vstack((arr1, arr2))\n",
    "print(\"Vertically stacked:\\n\", vertical_stack)  # Result: [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "# Horizontal stacking\n",
    "horizontal_stack = np.hstack((arr1, arr2))\n",
    "print(\"Horizontally stacked:\", horizontal_stack)  # Result: [1, 2, 3, 4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7eddf",
   "metadata": {},
   "source": [
    "#### Splitting Arrays\n",
    "\n",
    "* Splitting arrays is the opposite of combining them. It’s the process of breaking a single array into multiple smaller arrays. NumPy provides np.split(), np.hsplit(), and np.vsplit() functions for this purpose.\n",
    "\n",
    "* In np.split() function, the first argument is the array to be split, and the second argument is the number of equal parts or the specific indices at which to split the array. The result is a list of arrays, each representing a part of the original array.\n",
    "\n",
    "* np.hsplit() is used for splitting arrays horizontally (column-wise) and works on arrays of at least two dimensions. Similarly, np.vsplit() splits arrays vertically (row-wise) and also requires the array to be at least two-dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d75be0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array split into three equal parts: [array([1, 2]), array([3, 4]), array([5, 6])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Split into three equal parts\n",
    "split_arr = np.split(arr, 3) \n",
    "print(\"Array split into three equal parts:\", split_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ff15f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontally split array:\n",
      "Part 1:\n",
      " [[1]\n",
      " [4]\n",
      " [7]]\n",
      "Part 2:\n",
      " [[2]\n",
      " [5]\n",
      " [8]]\n",
      "Part 3:\n",
      " [[3]\n",
      " [6]\n",
      " [9]]\n",
      "\n",
      "Vertically split array:\n",
      "Part 1:\n",
      " [[1 2 3]]\n",
      "Part 2:\n",
      " [[4 5 6]]\n",
      "Part 3:\n",
      " [[7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a 2D array for demonstration\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Horizontal split - splits into 3 arrays along columns\n",
    "hsplit_arr = np.hsplit(arr_2d, 3)\n",
    "print(\"Horizontally split array:\")\n",
    "for i, arr in enumerate(hsplit_arr):\n",
    "    print(f\"Part {i+1}:\\n\", arr)\n",
    "\n",
    "# Creating another 2D array for vertical split\n",
    "# Note: np.vsplit() requires the array to be at least two-dimensional\n",
    "\n",
    "# Vertical split - splits into 3 arrays along rows\n",
    "vsplit_arr = np.vsplit(arr_2d, 3)\n",
    "print(\"\\nVertically split array:\")\n",
    "for i, arr in enumerate(vsplit_arr):\n",
    "    print(f\"Part {i+1}:\\n\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ee691",
   "metadata": {},
   "source": [
    "#### Alias vs. View vs. Copy of Arrays\n",
    "\n",
    "* Alias: An alias refers to multiple variables that all point to the same underlying NumPy array object. They share the same data in memory. Changes in alias array will affect the original array.\n",
    "\n",
    "* View: The .view() method creates a new array object that looks at the same data as the original array but does not share the same identity. It provides a way to view the data differently or with different data types, but it still operates on the same underlying data.\n",
    "\n",
    "* Copy: A copy is a completely independent duplicate of a NumPy array. It has its own data in memory, and changes made to the copy will not affect the original array, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c981834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [1 2 3]\n",
      "After modifying view_arr, original array changes to: [10  2  3]\n",
      "Original array reset to: [1 2 3]\n",
      "After modifying copy_arr, original array remains unchanged: [1 2 3]\n",
      "Modified copy array: [10  2  3]\n",
      "After modifying alias_arr, original array reflects the change: [ 1 20  3]\n"
     ]
    }
   ],
   "source": [
    "original_arr = np.array([1, 2, 3])\n",
    "print(\"Original array:\", original_arr)\n",
    "\n",
    "# Alias of original array\n",
    "alias_arr = original_arr\n",
    "# No change yet, so no print statement needed here for aliasing demonstration\n",
    "\n",
    "# Changes to view_arr will affect the original array\n",
    "view_arr = original_arr.view()\n",
    "# Making a change to view_arr to show its effect\n",
    "view_arr[0] = 10\n",
    "print(\"After modifying view_arr, original array changes to:\", original_arr)\n",
    "\n",
    "# Reset original array for clarity in demonstration\n",
    "original_arr[0] = 1\n",
    "print(\"Original array reset to:\", original_arr)\n",
    "\n",
    "# Changes to copy_arr won't affect the original array\n",
    "copy_arr = original_arr.copy()\n",
    "# Making a change to copy_arr to show it doesn't affect original_arr\n",
    "copy_arr[0] = 10\n",
    "print(\"After modifying copy_arr, original array remains unchanged:\", original_arr)\n",
    "print(\"Modified copy array:\", copy_arr)\n",
    "\n",
    "# Now, demonstrating aliasing by modifying alias_arr\n",
    "alias_arr[1] = 20\n",
    "print(\"After modifying alias_arr, original array reflects the change:\", original_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e24ed",
   "metadata": {},
   "source": [
    "#### Sorting Numpy Arrays\n",
    "\n",
    "You can use np.sort(array) to sort the array in ascending order, however for descending you have to use the trick of array slicing [::-1], which reverses the array elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba2947d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [3 1 5 2 4]\n",
      "Data sorted in ascending order: [1 2 3 4 5]\n",
      "Data sorted in descending order: [5 4 3 2 1]\n",
      "Indices that would sort the array: [1 3 0 4 2]\n",
      "Data sorted using indices: [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([3, 1, 5, 2, 4])\n",
    "print(\"Original data:\", data)\n",
    "\n",
    "# Sorting the data in ascending order\n",
    "sorted_data = np.sort(data)  # Ascending order\n",
    "print(\"Data sorted in ascending order:\", sorted_data)\n",
    "\n",
    "# Sorting the data in descending order\n",
    "reverse_sorted_data = np.sort(data)[::-1]  # Descending order\n",
    "print(\"Data sorted in descending order:\", reverse_sorted_data)\n",
    "\n",
    "# Returning indices that would sort the array\n",
    "sorted_indices = np.argsort(data)\n",
    "print(\"Indices that would sort the array:\", sorted_indices)\n",
    "\n",
    "# Demonstrating how to use sorted_indices to sort the array\n",
    "sorted_data_with_indices = data[sorted_indices]\n",
    "print(\"Data sorted using indices:\", sorted_data_with_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d987a92",
   "metadata": {},
   "source": [
    "### NumPy for Data Cleaning\n",
    "\n",
    "#### 1. Identifying Missing Values\n",
    "\n",
    "NumPy provides functions to check for missing values in a numeric array, represented as NaN (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa67c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with missing values: [ 1.  2. nan  4. nan  6.]\n",
      "Missing values in the array: [False False  True False  True False]\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array with missing values\n",
    "data = np.array([1, 2, np.nan, 4, np.nan, 6])\n",
    "print(\"Data with missing values:\", data)\n",
    "\n",
    "# Check for missing values\n",
    "has_missing = np.isnan(data)\n",
    "print(\"Missing values in the array:\", has_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cdd096",
   "metadata": {},
   "source": [
    "#### 2. Removing Rows or Columns with Missing Values\n",
    "\n",
    "We can use np.isnan to get a boolean matrix with True for the indices where there is a missing value. And when we pass it to np.any, it will return a 1D array with True for the index where any row item is True. And finally we ~ (not), and pass the boolean to the original Matrix, which will remove the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d663c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D array with missing values:\n",
      " [[ 1.  2.  3.]\n",
      " [ 4. nan  6.]\n",
      " [ 7.  8.  9.]]\n",
      "Cleaned data after removing rows with missing values:\n",
      " [[1. 2. 3.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D array with missing values\n",
    "data = np.array([[1, 2, 3], [4, np.nan, 6], [7, 8, 9]])\n",
    "print(\"Original 2D array with missing values:\\n\", data)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "cleaned_data = data[~np.any(np.isnan(data), axis=1)]\n",
    "print(\"Cleaned data after removing rows with missing values:\\n\", cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b4788d",
   "metadata": {},
   "source": [
    "### NumPy for Statistical Analysis\n",
    "\n",
    "### Data Transformation\n",
    "\n",
    "Numpy doesn’t have the data transformation features directly, but we can utilize the existing features to perform these.\n",
    "\n",
    "#### 1. Data Centering\n",
    "Centering data involves subtracting the mean from each data point. This is often done to remove the effect of a constant term or to facilitate model convergence.\n",
    "\n",
    "#### 2. Standardization\n",
    "This to transform numerical data in such a way that it has a mean of 0 and a standard deviation of 1. This process makes it easier to compare and analyze data with different scales.\n",
    "\n",
    "#### 3. Log Transformation\n",
    "Logarithmic transformation is used to make data more symmetric or to stabilize variance in cases of exponential growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b05395fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [10 20 30 40 50]\n",
      "Centered data (subtracting the mean): [-20. -10.   0.  10.  20.]\n",
      "\n",
      "Standard deviation of the data: 14.142135623730951\n",
      "Standardized data (subtracting the mean and dividing by the standard deviation): [-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n",
      "\n",
      "Log-transformed data: [2.30258509 2.99573227 3.40119738 3.68887945 3.91202301]\n"
     ]
    }
   ],
   "source": [
    "# Data Centering\n",
    "data = np.array([10, 20, 30, 40, 50])\n",
    "mean = np.mean(data)\n",
    "centered_data = data - mean\n",
    "print(\"Original data:\", data)\n",
    "print(\"Centered data (subtracting the mean):\", centered_data)\n",
    "\n",
    "# Standardization\n",
    "std_dev = np.std(data)\n",
    "standardized_data = (data - mean) / std_dev\n",
    "print(\"\\nStandard deviation of the data:\", std_dev)\n",
    "print(\"Standardized data (subtracting the mean and dividing by the standard deviation):\", standardized_data)\n",
    "\n",
    "# Log Transformation\n",
    "log_transformed_data = np.log(data)\n",
    "print(\"\\nLog-transformed data:\", log_transformed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed00b2",
   "metadata": {},
   "source": [
    "### Random Sampling\n",
    "\n",
    "Random sampling involves selecting a subset of data points from a larger dataset. NumPy also provides tools for generating random numbers from various probability distributions.\n",
    "\n",
    "#### 1. Simple Random Sampling: \n",
    "Select a random sample of a specified size from a dataset. When sampling without replacement, each item selected is not returned to the population.\n",
    "\n",
    "#### 2. Bootstrap Sampling: \n",
    "Bootstrap sampling involves sampling with replacement to create multiple datasets. This is often used for estimating statistics’ variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "177ddaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "Random samples without replacement: [9 2 5 4 3]\n",
      "\n",
      "Number of bootstrap samples: 1000\n",
      "Example of one bootstrap sample: [3 7 9 6 4 9 8 6 9 8]\n",
      "Each bootstrap sample contains the same number of elements as the original data but with replacement.\n"
     ]
    }
   ],
   "source": [
    "# Simple Random Sampling Without replacement\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "random_samples = np.random.choice(data, size=5, replace=False)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Random samples without replacement:\", random_samples)\n",
    "\n",
    "# Bootstrap Sampling\n",
    "num_samples = 1000\n",
    "bootstrap_samples = np.random.choice(data, size=(num_samples, len(data)), replace=True)\n",
    "print(\"\\nNumber of bootstrap samples:\", num_samples)\n",
    "print(\"Example of one bootstrap sample:\", bootstrap_samples[0])\n",
    "print(\"Each bootstrap sample contains the same number of elements as the original data but with replacement.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be478367",
   "metadata": {},
   "source": [
    "### Structured Arrays\n",
    "\n",
    "Structured arrays allow you to work with data similar to a table with named columns. Each element of a structured array can have different data types. Create your datatypes by using np.dtype and add the column name and datatype as a tuple. Then you can pass it to your array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "460610db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured array of employees: [(b'Alice', 30, 50000.) (b'Bob', 25, 60000.)]\n",
      "\n",
      "Name of the first employee: Alice\n",
      "Ages of all employees: [30 25]\n"
     ]
    }
   ],
   "source": [
    "# Define data types for fields\n",
    "dt = np.dtype([('name', 'S20'), ('age', int), ('salary', float)])\n",
    "\n",
    "# Create a structured array\n",
    "employees = np.array([('Alice', 30, 50000.0), ('Bob', 25, 60000.0)], dtype=dt)\n",
    "print(\"Structured array of employees:\", employees)\n",
    "\n",
    "# Access the 'name' field of the first employee\n",
    "print(\"\\nName of the first employee:\", employees['name'][0].decode('utf-8'))\n",
    "\n",
    "# Access the 'age' field of all employees\n",
    "print(\"Ages of all employees:\", employees['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004b016",
   "metadata": {},
   "source": [
    "## Pandas: \n",
    "\n",
    "### Setting up Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f182e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bce54",
   "metadata": {},
   "source": [
    "### Data Structures:\n",
    "\n",
    "Pandas provides two fundamental data structures: Series and DataFrame, which are the building blocks of data manipulation and analysis in Python. Understanding these data structures is essential for effective data handling with Pandas.\n",
    "\n",
    "#### Series\n",
    "\n",
    "A Series is a one-dimensional labeled array that can hold various data types, such as integers, floats, strings, or even custom objects. It’s similar to a column in an Excel spreadsheet or a single column in a SQL table. Key features of the Series include:\n",
    "\n",
    "* Labeling: Each element in a Series has a label or an index, which allows for easy access and manipulation of data.\n",
    "* Homogeneous Data: Unlike lists in Python, Series typically stores data of the same data type, ensuring consistency.\n",
    "* Vectorized Operations: You can perform vectorized operations on Series, making it efficient for element-wise calculations. This feature allows you to efficiently perform operations on entire columns or Series without the need for explicit loops. You can add, subtract, and multiply the series (columns of a dataframe) with a series or scalar.\n",
    "\n",
    "#### Creating a Series\n",
    "\n",
    "Let's explore different ways to create a Series in Pandas:\n",
    "\n",
    "* From a List: The most straightforward method, akin to jotting down a list of items on a piece of paper.\n",
    "* From a Dictionary: Where each key-value pair becomes an index-data pair in the Series, like mapping names to phone numbers in an address book.\n",
    "* From a NumPy Array: It is like transforming a NumPy array into a Series with additional capabilities like having custom index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bb8b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series from a list:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "\n",
      "Series from a dictionary:\n",
      " a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "\n",
      "Series from a NumPy array:\n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series from a list\n",
    "series_from_list = pd.Series([1, 2, 3, 4, 5])\n",
    "print(\"Series from a list:\\n\", series_from_list)\n",
    "\n",
    "# Creating a Series from a dictionary\n",
    "series_from_dict = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
    "print(\"\\nSeries from a dictionary:\\n\", series_from_dict)\n",
    "\n",
    "# Creating a Series from a NumPy array\n",
    "series_from_array = pd.Series(np.array([10, 20, 30, 40, 50]))\n",
    "print(\"\\nSeries from a NumPy array:\\n\", series_from_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd4e74",
   "metadata": {},
   "source": [
    "#### DataFrame\n",
    "A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). Imagine a DataFrame as a whole spreadsheet or a SQL table. It's like a collection of Series objects that share the same index, perfect for storing real-world data like sales reports, sports statistics, etc.\n",
    "\n",
    "Key features of DataFrames include:\n",
    "\n",
    "* Columns: Each column in a DataFrame is a Series, which means it can hold different data types.\n",
    "* Indexing: DataFrames have both row and column indexes, allowing for flexible data selection.\n",
    "* Data Alignment: Like Series, DataFrames can align data based on labels, making operations easy and intuitive.\n",
    "* Data Integration: You can merge, join, and concatenate DataFrames to combine and analyze data from various sources.\n",
    "\n",
    "#### Creating a DataFrame\n",
    "\n",
    "Creating a DataFrame can be done in several ways, reflecting the versatility of Pandas:\n",
    "\n",
    "* From a Dictionary of Lists: Where keys become column names and lists become column data.\n",
    "* From a List of Dictionaries: Each dictionary in the list becomes a row in the DataFrame.\n",
    "* From a List of Lists: Combined with a separate list of column names to label the data.\n",
    "* From a Series: You can build a DataFrame from one or more Series objects. If you use multiple Series, Pandas aligns them by their indexes.\n",
    "* From a NumPy Array: Similar to Series, but now you can have a multi-dimensional array forming a table-like structure. You can specify column names separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "502edc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from a dictionary of lists:\n",
      "    A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "DataFrame from a list of dictionaries:\n",
      "    A  B  C\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "\n",
      "DataFrame from a list of lists:\n",
      "    A  B  C\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "DataFrame from Series:\n",
      "    Column1  Column2\n",
      "a        1        4\n",
      "b        2        5\n",
      "c        3        6\n",
      "\n",
      "DataFrame from a NumPy array:\n",
      "    ColumnA  ColumnB  ColumnC\n",
      "0        1        2        3\n",
      "1        4        5        6\n",
      "2        7        8        9\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame from a dictionary of lists\n",
    "df_from_dict = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "print(\"DataFrame from a dictionary of lists:\\n\", df_from_dict)\n",
    "\n",
    "# Creating a DataFrame from a list of dictionaries\n",
    "df_from_list_of_dicts = pd.DataFrame([{'A': 1, 'B': 2, 'C': 3}, {'A': 4, 'B': 5, 'C': 6}])\n",
    "print(\"\\nDataFrame from a list of dictionaries:\\n\", df_from_list_of_dicts)\n",
    "\n",
    "# Creating a DataFrame from a list of lists\n",
    "df_from_list_of_lists = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=['A', 'B', 'C'])\n",
    "print(\"\\nDataFrame from a list of lists:\\n\", df_from_list_of_lists)\n",
    "\n",
    "# Creating a DataFrame from a Series\n",
    "series1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "series2 = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "df_from_series = pd.DataFrame({'Column1': series1, 'Column2': series2})\n",
    "print(\"DataFrame from Series:\\n\", df_from_series)\n",
    "\n",
    "# Creating a DataFrame from a NumPy array\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "df_from_np_array = pd.DataFrame(np_array, columns=['ColumnA', 'ColumnB', 'ColumnC'])\n",
    "print(\"\\nDataFrame from a NumPy array:\\n\", df_from_np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a958fc",
   "metadata": {},
   "source": [
    "Understanding these two core data structures sets the foundation for efficient data manipulation and analysis using Pandas. They enable you to load, clean, explore, and transform data in various ways, making Pandas a powerful tool in the data scientist’s toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71686592",
   "metadata": {},
   "source": [
    "### Data Loading and Data Inspection\n",
    "\n",
    "Pandas provides a wide range of functions and methods for efficiently loading data from various sources and formats into DataFrames.\n",
    "\n",
    "#### Reading Data from Different Sources (CSV, Excel, Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3da3a9b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data from csv file with the name - data.csv\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load data from excel file with the name - data.xlsx\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_excel \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/mambaforge/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/mambaforge/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/mambaforge/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/mambaforge/envs/myenv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "# Load data from csv file with the name - data.csv\n",
    "df_csv = pd.read_csv('data.csv')\n",
    "\n",
    "# Load data from excel file with the name - data.xlsx\n",
    "df_excel = pd.read_excel('data.xlsx')\n",
    "\n",
    "# You can specify a specific sheet using the sheet_name parameter\n",
    "df_sheet1 = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Load data from a JSON file\n",
    "df_json = pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c17e1",
   "metadata": {},
   "source": [
    "### Case Study: Product Sales Analysis for TechGear\n",
    "\n",
    "This case study will involve a fictional online retail company, \"TechGear,\" which sells technology gadgets and accessories.\n",
    "\n",
    "Objective: Analyze TechGear's sales data to understand sales trends, customer preferences, product performance, and inventory management for the fiscal year 2024.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e210bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data creation\n",
    "data = {\n",
    "    'TransactionID': range(1, 21),\n",
    "    'Date': pd.date_range(start='2024-01-01', periods=20, freq='D'),\n",
    "    'CustomerID': [101, 102, 103, 104, 101, 102, 103, 104, 101, 102, 103, 104, 101, 102, 103, 104, 101, 102, 103, 104],\n",
    "    'ProductName': ['Laptop', 'Mouse', 'Keyboard', 'Headphones', 'Laptop', 'Mouse', 'Keyboard', 'Headphones', 'Laptop', 'Mouse', 'Keyboard', 'Headphones', 'Laptop', 'Mouse', 'Keyboard', 'Headphones', 'Laptop', 'Mouse', 'Keyboard', 'Headphones'],\n",
    "    'Category': ['Electronics', 'Accessories', 'Accessories', 'Accessories', 'Electronics', 'Accessories', 'Accessories', 'Accessories', 'Electronics', 'Accessories', 'Accessories', 'Accessories', 'Electronics', 'Accessories', 'Accessories', 'Accessories', 'Electronics', 'Accessories', 'Accessories', 'Accessories'],\n",
    "    'Quantity': [1, 2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1],\n",
    "    'Price': [1000, 20, 30, 50, 1000, 20, 30, 50, 1000, 20, 30, 50, 1000, 20, 30, 50, 1000, 20, 30, 50]\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "sales_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ce059",
   "metadata": {},
   "source": [
    "### Displaying DataFrames\n",
    "\n",
    "It’s nice that we loaded the data, but how do we see it, right? Displaying a data frame is the first step in understanding its contents. you can just type the data frame name and execute the cell to see the top 5 and bottom 5 rows. And Pandas offers several othermethods to display different portions of your data frame:\n",
    "\n",
    "* head(n): This method displays the first n rows of the data frame. It's useful for getting a quick overview of the data's structure without overwhelming yourself with too much information, or if you just want to see the column names, you can use .columns\n",
    "* tail(n): Similar to .head(), this method shows the last n rows of the DataFrame. It's handy for checking the end of the dataset.\n",
    "* sample(n): If you want to see random rows from the DataFrame, use this method. This is useful for exploring diverse parts of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d17c29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID       Date  CustomerID ProductName     Category  Quantity  \\\n",
       "0              1 2024-01-01         101      Laptop  Electronics         1   \n",
       "1              2 2024-01-02         102       Mouse  Accessories         2   \n",
       "2              3 2024-01-03         103    Keyboard  Accessories         3   \n",
       "3              4 2024-01-04         104  Headphones  Accessories         1   \n",
       "4              5 2024-01-05         101      Laptop  Electronics         1   \n",
       "5              6 2024-01-06         102       Mouse  Accessories         2   \n",
       "6              7 2024-01-07         103    Keyboard  Accessories         3   \n",
       "7              8 2024-01-08         104  Headphones  Accessories         1   \n",
       "8              9 2024-01-09         101      Laptop  Electronics         1   \n",
       "9             10 2024-01-10         102       Mouse  Accessories         2   \n",
       "\n",
       "   Price  \n",
       "0   1000  \n",
       "1     20  \n",
       "2     30  \n",
       "3     50  \n",
       "4   1000  \n",
       "5     20  \n",
       "6     30  \n",
       "7     50  \n",
       "8   1000  \n",
       "9     20  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "sales_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e0407bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TransactionID       Date  CustomerID ProductName     Category  Quantity  \\\n",
       "10             11 2024-01-11         103    Keyboard  Accessories         3   \n",
       "11             12 2024-01-12         104  Headphones  Accessories         1   \n",
       "12             13 2024-01-13         101      Laptop  Electronics         1   \n",
       "13             14 2024-01-14         102       Mouse  Accessories         2   \n",
       "14             15 2024-01-15         103    Keyboard  Accessories         3   \n",
       "15             16 2024-01-16         104  Headphones  Accessories         1   \n",
       "16             17 2024-01-17         101      Laptop  Electronics         1   \n",
       "17             18 2024-01-18         102       Mouse  Accessories         2   \n",
       "18             19 2024-01-19         103    Keyboard  Accessories         3   \n",
       "19             20 2024-01-20         104  Headphones  Accessories         1   \n",
       "\n",
       "    Price  \n",
       "10     30  \n",
       "11     50  \n",
       "12   1000  \n",
       "13     20  \n",
       "14     30  \n",
       "15     50  \n",
       "16   1000  \n",
       "17     20  \n",
       "18     30  \n",
       "19     50  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the last 10 rows\n",
    "print(\"\\nLast 10 rows:\")\n",
    "sales_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d433c421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample of 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>104</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>102</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>101</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>103</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TransactionID       Date  CustomerID ProductName     Category  Quantity  \\\n",
       "8               9 2024-01-09         101      Laptop  Electronics         1   \n",
       "7               8 2024-01-08         104  Headphones  Accessories         1   \n",
       "18             19 2024-01-19         103    Keyboard  Accessories         3   \n",
       "5               6 2024-01-06         102       Mouse  Accessories         2   \n",
       "3               4 2024-01-04         104  Headphones  Accessories         1   \n",
       "1               2 2024-01-02         102       Mouse  Accessories         2   \n",
       "11             12 2024-01-12         104  Headphones  Accessories         1   \n",
       "17             18 2024-01-18         102       Mouse  Accessories         2   \n",
       "4               5 2024-01-05         101      Laptop  Electronics         1   \n",
       "6               7 2024-01-07         103    Keyboard  Accessories         3   \n",
       "\n",
       "    Price  \n",
       "8    1000  \n",
       "7      50  \n",
       "18     30  \n",
       "5      20  \n",
       "3      50  \n",
       "1      20  \n",
       "11     50  \n",
       "17     20  \n",
       "4    1000  \n",
       "6      30  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a random sample of 10 rows\n",
    "print(\"\\nRandom sample of 10 rows:\")\n",
    "sales_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00583354",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Pandas provides methods for obtaining fundamental insights into your data. These are the first things you need to check while exploring your data.\n",
    "\n",
    "* .shape : This function gives a set where the first element specifies the no.of samples/rows in the data and the second element specifies the no.of columns.\n",
    "* .info(): This method provides a concise summary of the DataFrame, including the data types, non-null counts, and memory usage. It's an excellent starting point for understanding the data's structure, or if you just want to see the data types, you can use .dtypes\n",
    "* .describe(): The method generates basic statistics for each numeric column in the DataFrame, such as count, mean, standard deviation, minimum, and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e26b8310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape: (20, 7)\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   TransactionID  20 non-null     int64         \n",
      " 1   Date           20 non-null     datetime64[ns]\n",
      " 2   CustomerID     20 non-null     int64         \n",
      " 3   ProductName    20 non-null     object        \n",
      " 4   Category       20 non-null     object        \n",
      " 5   Quantity       20 non-null     int64         \n",
      " 6   Price          20 non-null     int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 1.2+ KB\n",
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>20</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>2024-01-10 12:00:00</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "      <td>2024-01-05 18:00:00</td>\n",
       "      <td>101.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>2024-01-10 12:00:00</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "      <td>2024-01-15 06:00:00</td>\n",
       "      <td>103.250000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>287.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>2024-01-20 00:00:00</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.147079</td>\n",
       "      <td>0.850696</td>\n",
       "      <td>429.595893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionID                 Date  CustomerID   Quantity        Price\n",
       "count       20.00000                   20   20.000000  20.000000    20.000000\n",
       "mean        10.50000  2024-01-10 12:00:00  102.500000   1.750000   275.000000\n",
       "min          1.00000  2024-01-01 00:00:00  101.000000   1.000000    20.000000\n",
       "25%          5.75000  2024-01-05 18:00:00  101.750000   1.000000    27.500000\n",
       "50%         10.50000  2024-01-10 12:00:00  102.500000   1.500000    40.000000\n",
       "75%         15.25000  2024-01-15 06:00:00  103.250000   2.250000   287.500000\n",
       "max         20.00000  2024-01-20 00:00:00  104.000000   3.000000  1000.000000\n",
       "std          5.91608                  NaN    1.147079   0.850696   429.595893"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shape of the DataFrame\n",
    "print(\"\\nDataFrame shape:\", sales_df.shape)\n",
    "\n",
    "# Display concise summary\n",
    "print(\"\\nDataFrame info:\")\n",
    "sales_df.info()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baac93e3",
   "metadata": {},
   "source": [
    "For categorical or discrete data, you can explore unique values and their frequencies:\n",
    "\n",
    "* .nunique(): This method calculates the number of unique values in each column. It's handy for understanding the diversity of data in categorical columns.\n",
    "* .column_name or ['column_name'] : To access a specific column in the DataFrame. You can only use the second approach when the column name has spaces.  \n",
    "* .value_counts(): Use this method on a specific column to count the occurrences of each unique value. It's particularly useful for categorical columns.\n",
    "* Basic Statistics: You can calculate additional statistics for specific columns, such as the sum, max, min, mean, median, or mode, using Pandas’ mathematical functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2618467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Product Names:\n",
      "['Laptop' 'Mouse' 'Keyboard' 'Headphones']\n",
      "\n",
      "Category Value Counts:\n",
      "Category\n",
      "Accessories    15\n",
      "Electronics     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Price Statistics:\n",
      "count      20.000000\n",
      "mean      275.000000\n",
      "std       429.595893\n",
      "min        20.000000\n",
      "25%        27.500000\n",
      "50%        40.000000\n",
      "75%       287.500000\n",
      "max      1000.000000\n",
      "Name: Price, dtype: float64\n",
      "\n",
      "Average Quantity Sold:\n",
      "1.75\n"
     ]
    }
   ],
   "source": [
    "# Unique product names\n",
    "print(\"\\nUnique Product Names:\")\n",
    "print(sales_df['ProductName'].unique())\n",
    "\n",
    "# Value counts for 'Category'\n",
    "print(\"\\nCategory Value Counts:\")\n",
    "print(sales_df['Category'].value_counts())\n",
    "\n",
    "# Basic statistics for 'Price'\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(sales_df['Price'].describe())\n",
    "\n",
    "# Mean quantity sold\n",
    "print(\"\\nAverage Quantity Sold:\")\n",
    "print(sales_df['Quantity'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5dc4ab",
   "metadata": {},
   "source": [
    "Based on the analysis, we can derive insights such as the most popular product categories, average spending per transaction, and customer buying patterns. These insights can help TechGear in decision-making processes related to inventory management, marketing strategies, and customer engagement initiatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc72e8",
   "metadata": {},
   "source": [
    "### Data Selection and Indexing\n",
    "\n",
    "Data selection and indexing are fundamental operations in Pandas, allowing you to extract specific subsets of data from a DataFrame.\n",
    "\n",
    "#### Selecting Columns and Rows\n",
    "\n",
    "You can select specific columns and rows from a DataFrame using square brackets [], .loc[], and .iloc[] indexing methods:\n",
    "\n",
    "1. Using Square Brackets []: To select one or more columns by their names, you can use square brackets with the column names as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d1e61f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>New York</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Houston</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Eva</td>\n",
       "      <td>28</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Frank</td>\n",
       "      <td>22</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Grace</td>\n",
       "      <td>55</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>65</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Ian</td>\n",
       "      <td>20</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Jack</td>\n",
       "      <td>45</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID     Name  Age          City  Salary\n",
       "0         101    Alice   25      New York   50000\n",
       "1         102      Bob   30   Los Angeles   60000\n",
       "2         103  Charlie   35       Chicago   55000\n",
       "3         104    David   40       Houston   65000\n",
       "4         105      Eva   28       Phoenix   70000\n",
       "5         106    Frank   22  Philadelphia   52000\n",
       "6         107    Grace   55   San Antonio   58000\n",
       "7         108   Hannah   65     San Diego   62000\n",
       "8         109      Ian   20        Dallas   60000\n",
       "9         110     Jack   45      San Jose   64000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'CustomerID': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah', 'Ian', 'Jack'],\n",
    "    'Age': [25, 30, 35, 40, 28, 22, 55, 65, 20, 45],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose'],\n",
    "    'Salary': [50000, 60000, 55000, 65000, 70000, 52000, 58000, 62000, 60000, 64000]\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "customers_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b001f0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace</td>\n",
       "      <td>San Antonio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ian</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jack</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name          City\n",
       "0    Alice      New York\n",
       "1      Bob   Los Angeles\n",
       "2  Charlie       Chicago\n",
       "3    David       Houston\n",
       "4      Eva       Phoenix\n",
       "5    Frank  Philadelphia\n",
       "6    Grace   San Antonio\n",
       "7   Hannah     San Diego\n",
       "8      Ian        Dallas\n",
       "9     Jack      San Jose"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = customers_df[['Name', 'City']]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448b9b4",
   "metadata": {},
   "source": [
    "2. Using .loc[] For Label-Based Selection: The .loc[] indexer allows you to select rows and columns by label. You can specify both row and column labels. If you specify multiple rows or columns using index slicing, the inner and outer indices both are inclusive. Hence, 3,4,5,6 all the rows are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5a3554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eva</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age\n",
       "2  Charlie   35\n",
       "3    David   40\n",
       "4      Eva   28\n",
       "5    Frank   22"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data = customers_df.loc[2:5, ['Name', 'Age']]\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb1c59",
   "metadata": {},
   "source": [
    "3. Using .iloc[] For Integer-Based Selection: The .iloc[] indexer lets you select rows and columns by integer location, which is useful for numeric indexing.\n",
    "If you specify multiple rows or columns using index slicing, only the inner is inclusive, and the outer is exclusive. Hence only 1,2,3 rows will be shown and 0,1 columns will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3c4e074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID     Name\n",
       "1         102      Bob\n",
       "2         103  Charlie\n",
       "3         104    David"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data = customers_df.iloc[1:4, 0:2]\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f3bab",
   "metadata": {},
   "source": [
    "#### Filtering / Conditional Selection\n",
    "\n",
    "Conditional selection enables you to filter rows based on specific criteria. You can use boolean indexing to achieve this. When you pass a list of booleans ( length = length of samples/rows ) to a data frame, the data frame selects the specific rows where the index of the boolean list is True.\n",
    "\n",
    "1. Boolean Indexing: Create a boolean mask by applying a condition to a column, and then use this mask to filter rows for the True Condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7c1114b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Houston</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Eva</td>\n",
       "      <td>28</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>65</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Jack</td>\n",
       "      <td>45</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID    Name  Age       City  Salary\n",
       "3         104   David   40    Houston   65000\n",
       "4         105     Eva   28    Phoenix   70000\n",
       "7         108  Hannah   65  San Diego   62000\n",
       "9         110    Jack   45   San Jose   64000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_mask = customers_df['Salary'] > 60000\n",
    "filtered_data = customers_df[boolean_mask]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac374a6",
   "metadata": {},
   "source": [
    "2. Multiple Conditions: Combine multiple conditions using logical operators (& for AND, | for OR) and use parentheses for clarity. or you can also use .isin() a method of pandas when you want to check if a value from a list of things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05df029c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Houston</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Eva</td>\n",
       "      <td>28</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Grace</td>\n",
       "      <td>55</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>65</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Jack</td>\n",
       "      <td>45</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID    Name  Age         City  Salary\n",
       "1         102     Bob   30  Los Angeles   60000\n",
       "3         104   David   40      Houston   65000\n",
       "4         105     Eva   28      Phoenix   70000\n",
       "6         107   Grace   55  San Antonio   58000\n",
       "7         108  Hannah   65    San Diego   62000\n",
       "9         110    Jack   45     San Jose   64000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To filter customers older than 25 and with a salary greater than 55,000:\n",
    "boolean_mask = (customers_df['Age'] > 25) & (customers_df['Salary'] > 55000)\n",
    "filtered_data = customers_df[boolean_mask]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff885702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>65</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Ian</td>\n",
       "      <td>20</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID    Name  Age       City  Salary\n",
       "7         108  Hannah   65  San Diego   62000\n",
       "8         109     Ian   20     Dallas   60000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To filter customers either older than 60 or younger than 22:\n",
    "boolean_mask = (customers_df['Age'] > 60) | (customers_df['Age'] < 22)\n",
    "filtered_data = customers_df[boolean_mask]\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db95955",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Data cleaning is a critical step in the data preparation process. It involves identifying and addressing issues in your dataset to ensure its quality and reliability.\n",
    "\n",
    "The dataset we will be using for this activity is from Kaggle. \n",
    "\n",
    "Kaggle is an online platform that hosts data science competitions, datasets, and other resources. It allows users to find and publish datasets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n",
    "\n",
    "https://www.kaggle.com/datasets/tanishqdublish/grocery-dataset?resource=download\n",
    "Scraped Grocery Data from Costco's online marketplace.\n",
    "\n",
    "#### 1. Handling Missing Data\n",
    "\n",
    "Missing data is a common issue in real-world datasets. Pandas offers methods to handle missing values effectively.\n",
    "\n",
    "* .isna()and .notna(): These methods allow you to identify missing (NaN) and non-missing values, respectively, in your DataFrame. Applying this method for a column will return the boolean list with True for the indices where there is a missing value. And passing this list to a dataframe will return the rows where that column values are null.\n",
    "* .fillna(): You can replace missing values with a specified value or a calculated value using the .fillna() method. The below example replaces all the null values with zeros and directly modifies the data as we used in place = True.\n",
    "* .dropna(): Use this method to remove rows or columns containing missing values. By default, it will remove the rows ( axis = 0) where any of the column values is missing ( how = ‘any’ ).\n",
    "\n",
    "Note:\n",
    "- By Using how = ‘any’, it will drop the rows where any of the column values are missing.\n",
    "- By using how = ‘all’, it will drop the rows where all of the specified column values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74a1fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$56.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.3 out of 5 stars based on 265 reviews.</td>\n",
       "      <td>David’s Cookies Mile High Peanut Butter Cake, ...</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\"\" Peanut Butter Cake\\nCertified Kosher OU-...</td>\n",
       "      <td>A cake the dessert epicure will die for!Our To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$159.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 5 out of 5 stars based on 1 reviews.</td>\n",
       "      <td>The Cake Bake Shop 8\" Round Carrot Cake (16-22...</td>\n",
       "      <td>$</td>\n",
       "      <td>Spiced Carrot Cake with Cream Cheese Frosting ...</td>\n",
       "      <td>Due to the perishable nature of this item, ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$44.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.1 out of 5 stars based on 441 reviews.</td>\n",
       "      <td>St Michel Madeleine, Classic French Sponge Cak...</td>\n",
       "      <td>$</td>\n",
       "      <td>100 count\\nIndividually wrapped\\nMade in and I...</td>\n",
       "      <td>Moist and buttery sponge cakes with the tradit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$39.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.7 out of 5 stars based on 9459 reviews.</td>\n",
       "      <td>David's Cookies Butter Pecan Meltaways 32 oz, ...</td>\n",
       "      <td>$</td>\n",
       "      <td>Butter Pecan Meltaways\\n32 oz 2-Pack\\nNo Prese...</td>\n",
       "      <td>These delectable butter pecan meltaways are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.5 out of 5 stars based on 758 reviews.</td>\n",
       "      <td>David’s Cookies Premier Chocolate Cake, 7.2 lb...</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\" Four Layer Chocolate Cake\\nCertified Kosh...</td>\n",
       "      <td>A cake the dessert epicure will die for!To the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sub Category     Price     Discount  \\\n",
       "0  Bakery & Desserts   $56.99   No Discount   \n",
       "1  Bakery & Desserts  $159.99   No Discount   \n",
       "2  Bakery & Desserts   $44.99   No Discount   \n",
       "3  Bakery & Desserts   $39.99   No Discount   \n",
       "4  Bakery & Desserts   $59.99   No Discount   \n",
       "\n",
       "                                            Rating  \\\n",
       "0   Rated 4.3 out of 5 stars based on 265 reviews.   \n",
       "1       Rated 5 out of 5 stars based on 1 reviews.   \n",
       "2   Rated 4.1 out of 5 stars based on 441 reviews.   \n",
       "3  Rated 4.7 out of 5 stars based on 9459 reviews.   \n",
       "4   Rated 4.5 out of 5 stars based on 758 reviews.   \n",
       "\n",
       "                                               Title Currency  \\\n",
       "0  David’s Cookies Mile High Peanut Butter Cake, ...        $   \n",
       "1  The Cake Bake Shop 8\" Round Carrot Cake (16-22...        $   \n",
       "2  St Michel Madeleine, Classic French Sponge Cak...        $   \n",
       "3  David's Cookies Butter Pecan Meltaways 32 oz, ...        $   \n",
       "4  David’s Cookies Premier Chocolate Cake, 7.2 lb...        $   \n",
       "\n",
       "                                             Feature  \\\n",
       "0  \"10\"\" Peanut Butter Cake\\nCertified Kosher OU-...   \n",
       "1  Spiced Carrot Cake with Cream Cheese Frosting ...   \n",
       "2  100 count\\nIndividually wrapped\\nMade in and I...   \n",
       "3  Butter Pecan Meltaways\\n32 oz 2-Pack\\nNo Prese...   \n",
       "4  \"10\" Four Layer Chocolate Cake\\nCertified Kosh...   \n",
       "\n",
       "                                 Product Description  \n",
       "0  A cake the dessert epicure will die for!Our To...  \n",
       "1  Due to the perishable nature of this item, ord...  \n",
       "2  Moist and buttery sponge cakes with the tradit...  \n",
       "3  These delectable butter pecan meltaways are th...  \n",
       "4  A cake the dessert epicure will die for!To the...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'CostcoDataset.csv'\n",
    "grocery_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "grocery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7eed8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display the entire text of a column\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b31d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$56.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.3 out of 5 stars based on 265 reviews.</td>\n",
       "      <td>David’s Cookies Mile High Peanut Butter Cake, 6.8 lbs (14 Servings)</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\"\" Peanut Butter Cake\\nCertified Kosher OU-D\\n14 Servings</td>\n",
       "      <td>A cake the dessert epicure will die for!Our Top Selling Cake! Fudge brownie base, layered in velvety smooth peanut butter mousse, rich chocolate cake, topped with brownie chunks, handful of peanut butter chips, drizzled in fudge. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. -\\tGenerously sized precut slices, a cake lover’s dreams come true! Includes:Measures 10” diameterWeighs in at 6.8 lbs.14 servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$159.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 5 out of 5 stars based on 1 reviews.</td>\n",
       "      <td>The Cake Bake Shop 8\" Round Carrot Cake (16-22 Servings)</td>\n",
       "      <td>$</td>\n",
       "      <td>Spiced Carrot Cake with Cream Cheese Frosting   Silk Cherry Blossom Flowers (Not Edible)   No Nuts or Raisins   Dimensions: 9” Diameter, 7” High   16-22 Servings</td>\n",
       "      <td>Due to the perishable nature of this item, orders do NOT ship over the weekend. Orders can only be delivered on Wednesday, Thursday and Friday. Minimum delivery time is 5 business days.   Plate not included.   Gwendolyn Rogers' The Cake Bake Shop is famous for handcrafting magnificent and delicious cakes and desserts for her award winning restaurants. Each cake arrives beautifully packaged in her bakery’s signature pink and gold cake box with a pink satin ribbon and is topped with the bakery’s dusting of edible Pixie Glitter®, adding a sparkling finish to every dessert. Gwendolyn’s moist and delicious carrot cake is made with hand peeled and freshly grated carrots. Perfectly spiced with just the right amount of cinnamon, this cake has no nuts and no raisins. The three layers of spiced carrot cake are then filled and frosted with Gwendolyn's signature homemade cream cheese frosting. Topped with decorative pink silk cherry blossom flowers.   Features:   Flavor: Spiced Carrot Cake\\nCake Filling: Cream Cheese Frosting\\nCake Frosting: Cream Cheese Frosting\\nTopped with Pink Silk Cherry Blossom Flowers (cherry blossom flowers are not edible, please do not consume, remove before eating)\\nDimensions: 9” diameter, 7” high\\nServes 16-22\\nEach Cake Arrives With It’s Own Cake Care Card\\nAllergens: Contains Wheat, Milk, Soy, Egg\\nShips Frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$44.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.1 out of 5 stars based on 441 reviews.</td>\n",
       "      <td>St Michel Madeleine, Classic French Sponge Cake 100 - count</td>\n",
       "      <td>$</td>\n",
       "      <td>100 count\\nIndividually wrapped\\nMade in and Imported from France\\nFree-range eggs\\nNon-GMO ingredients</td>\n",
       "      <td>Moist and buttery sponge cakes with the traditional European madeleine flavor of almond. The Classic Madeleine is baked in the shape of seashell with ridges on one side and a “belly” on the other. Each madeleine is individually-wrapped for portion control and convenience.The Origin of the Madeleine: 18th century King Stanislas 1st, Duke of Lorraine During a festive dinner party in Commercy, France, the king’s chef abruptly left the kitchen. Seeking a solution to feed his guests dessert, a servant girl in the kitchen offered to make her family’s traditional pastry. The king enjoyed the little cake so much that he named it after the servant: Madeleine. Baked with non-GMO ingredients and free-range eggs. No preservatives, palm oil, hydrogenated oil or colorings. Baked with love in France.We all have our Madeleine moment:Enjoy everyday for breakfast, snack or dessert (Just as the French do!)Pack in lunches or backpacks for schoolServe during business, book club or PTA meetingsCut in half and fill with jelly or chocolate hazelnut spreadDecorate cakes or cupcakes with classic seashell shapeIncludes:100 countIndividually wrappedFree-range eggsNon-GMO ingredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$39.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.7 out of 5 stars based on 9459 reviews.</td>\n",
       "      <td>David's Cookies Butter Pecan Meltaways 32 oz, 2-pack</td>\n",
       "      <td>$</td>\n",
       "      <td>Butter Pecan Meltaways\\n32 oz 2-Pack\\nNo Preservatives\\nCertified Kosher OU-D\\nContains Nuts</td>\n",
       "      <td>These delectable butter pecan meltaways are the perfect snack or dessert for the whole family. The treats are made with pure creamy butter and large pecan chunks and have just the right amount of powdered sugar to satisfy your sweet tooth.Includes:Includes: 2 Tins (32 oz. each)Contains nutsNo preservativesEnjoy with your morning coffee or teaCookies can be stored at room temperature for up to 60 daysEach tin contains approximately 64 cookiesKosher OU-DSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.5 out of 5 stars based on 758 reviews.</td>\n",
       "      <td>David’s Cookies Premier Chocolate Cake, 7.2 lbs (Serves 14)</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\" Four Layer Chocolate Cake\\nCertified Kosher OU-D\\nServes 14</td>\n",
       "      <td>A cake the dessert epicure will die for!To the ultimate chocolate lover - We've baked your dream cake! Four split layers of our rich chocolate cake, filled with a smooth milk chocolate mousse, finished in chocolate ganache &amp; covered in dark chocolate bark pieces. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. Generously sized precut slices, A cake lover’s dreams come true! Includes:1 - 10” Premier Chocolate Overload CakeWeighs in at 7.2 lbs.14 Servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sub Category     Price     Discount  \\\n",
       "0  Bakery & Desserts   $56.99   No Discount   \n",
       "1  Bakery & Desserts  $159.99   No Discount   \n",
       "2  Bakery & Desserts   $44.99   No Discount   \n",
       "3  Bakery & Desserts   $39.99   No Discount   \n",
       "4  Bakery & Desserts   $59.99   No Discount   \n",
       "\n",
       "                                            Rating  \\\n",
       "0   Rated 4.3 out of 5 stars based on 265 reviews.   \n",
       "1       Rated 5 out of 5 stars based on 1 reviews.   \n",
       "2   Rated 4.1 out of 5 stars based on 441 reviews.   \n",
       "3  Rated 4.7 out of 5 stars based on 9459 reviews.   \n",
       "4   Rated 4.5 out of 5 stars based on 758 reviews.   \n",
       "\n",
       "                                                                 Title  \\\n",
       "0  David’s Cookies Mile High Peanut Butter Cake, 6.8 lbs (14 Servings)   \n",
       "1             The Cake Bake Shop 8\" Round Carrot Cake (16-22 Servings)   \n",
       "2          St Michel Madeleine, Classic French Sponge Cake 100 - count   \n",
       "3                 David's Cookies Butter Pecan Meltaways 32 oz, 2-pack   \n",
       "4          David’s Cookies Premier Chocolate Cake, 7.2 lbs (Serves 14)   \n",
       "\n",
       "  Currency  \\\n",
       "0        $   \n",
       "1        $   \n",
       "2        $   \n",
       "3        $   \n",
       "4        $   \n",
       "\n",
       "                                                                                                                                                             Feature  \\\n",
       "0                                                                                                       \"10\"\" Peanut Butter Cake\\nCertified Kosher OU-D\\n14 Servings   \n",
       "1  Spiced Carrot Cake with Cream Cheese Frosting   Silk Cherry Blossom Flowers (Not Edible)   No Nuts or Raisins   Dimensions: 9” Diameter, 7” High   16-22 Servings   \n",
       "2                                                            100 count\\nIndividually wrapped\\nMade in and Imported from France\\nFree-range eggs\\nNon-GMO ingredients   \n",
       "3                                                                       Butter Pecan Meltaways\\n32 oz 2-Pack\\nNo Preservatives\\nCertified Kosher OU-D\\nContains Nuts   \n",
       "4                                                                                                   \"10\" Four Layer Chocolate Cake\\nCertified Kosher OU-D\\nServes 14   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Product Description  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            A cake the dessert epicure will die for!Our Top Selling Cake! Fudge brownie base, layered in velvety smooth peanut butter mousse, rich chocolate cake, topped with brownie chunks, handful of peanut butter chips, drizzled in fudge. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. -\\tGenerously sized precut slices, a cake lover’s dreams come true! Includes:Measures 10” diameterWeighs in at 6.8 lbs.14 servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils  \n",
       "1  Due to the perishable nature of this item, orders do NOT ship over the weekend. Orders can only be delivered on Wednesday, Thursday and Friday. Minimum delivery time is 5 business days.   Plate not included.   Gwendolyn Rogers' The Cake Bake Shop is famous for handcrafting magnificent and delicious cakes and desserts for her award winning restaurants. Each cake arrives beautifully packaged in her bakery’s signature pink and gold cake box with a pink satin ribbon and is topped with the bakery’s dusting of edible Pixie Glitter®, adding a sparkling finish to every dessert. Gwendolyn’s moist and delicious carrot cake is made with hand peeled and freshly grated carrots. Perfectly spiced with just the right amount of cinnamon, this cake has no nuts and no raisins. The three layers of spiced carrot cake are then filled and frosted with Gwendolyn's signature homemade cream cheese frosting. Topped with decorative pink silk cherry blossom flowers.   Features:   Flavor: Spiced Carrot Cake\\nCake Filling: Cream Cheese Frosting\\nCake Frosting: Cream Cheese Frosting\\nTopped with Pink Silk Cherry Blossom Flowers (cherry blossom flowers are not edible, please do not consume, remove before eating)\\nDimensions: 9” diameter, 7” high\\nServes 16-22\\nEach Cake Arrives With It’s Own Cake Care Card\\nAllergens: Contains Wheat, Milk, Soy, Egg\\nShips Frozen  \n",
       "2                                                                                                                                                                                    Moist and buttery sponge cakes with the traditional European madeleine flavor of almond. The Classic Madeleine is baked in the shape of seashell with ridges on one side and a “belly” on the other. Each madeleine is individually-wrapped for portion control and convenience.The Origin of the Madeleine: 18th century King Stanislas 1st, Duke of Lorraine During a festive dinner party in Commercy, France, the king’s chef abruptly left the kitchen. Seeking a solution to feed his guests dessert, a servant girl in the kitchen offered to make her family’s traditional pastry. The king enjoyed the little cake so much that he named it after the servant: Madeleine. Baked with non-GMO ingredients and free-range eggs. No preservatives, palm oil, hydrogenated oil or colorings. Baked with love in France.We all have our Madeleine moment:Enjoy everyday for breakfast, snack or dessert (Just as the French do!)Pack in lunches or backpacks for schoolServe during business, book club or PTA meetingsCut in half and fill with jelly or chocolate hazelnut spreadDecorate cakes or cupcakes with classic seashell shapeIncludes:100 countIndividually wrappedFree-range eggsNon-GMO ingredients  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    These delectable butter pecan meltaways are the perfect snack or dessert for the whole family. The treats are made with pure creamy butter and large pecan chunks and have just the right amount of powdered sugar to satisfy your sweet tooth.Includes:Includes: 2 Tins (32 oz. each)Contains nutsNo preservativesEnjoy with your morning coffee or teaCookies can be stored at room temperature for up to 60 daysEach tin contains approximately 64 cookiesKosher OU-DSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           A cake the dessert epicure will die for!To the ultimate chocolate lover - We've baked your dream cake! Four split layers of our rich chocolate cake, filled with a smooth milk chocolate mousse, finished in chocolate ganache & covered in dark chocolate bark pieces. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. Generously sized precut slices, A cake lover’s dreams come true! Includes:1 - 10” Premier Chocolate Overload CakeWeighs in at 7.2 lbs.14 Servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ed8ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Sub Category              0\n",
      "Price                     3\n",
      "Discount                  0\n",
      "Rating                 1075\n",
      "Title                     0\n",
      "Currency                  5\n",
      "Feature                  18\n",
      "Product Description      42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying missing values in each column\n",
    "missing_values_count = grocery_df.isna().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cf197",
   "metadata": {},
   "source": [
    "#### In the below example we are replacing the missing value with zero.\n",
    "df['Column'].fillna(value=0, inplace=True)\n",
    "\n",
    "#### If you want to fill mising data with the mean of the numeric column\n",
    "df['Column'].fillna(value=df['Column'].mean(), inplace=True)\n",
    "\n",
    "#### If you want to fill mising data with the median of the numeric column\n",
    "df['Column'].fillna(value=df['Column'].median(), inplace=True)\n",
    "\n",
    "#### If you want to fill mising data with the mode of the categorical column\n",
    "df['Column'].fillna(value=df['Column'].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bba4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/q2977b1d2f11wv63sxv4cyhh0000gn/T/ipykernel_60878/3891675625.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  grocery_df['Rating'].fillna(value='No Rating', inplace=True)\n",
      "/var/folders/gl/q2977b1d2f11wv63sxv4cyhh0000gn/T/ipykernel_60878/3891675625.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  grocery_df['Feature'].fillna(value='No Features listed', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Example of filling missing data in the 'Rating' column with 'No Rating'\n",
    "grocery_df['Rating'].fillna(value='No Rating', inplace=True)\n",
    "\n",
    "# Example of filling missing data in the 'Feature' column with 'No Features listed'\n",
    "grocery_df['Feature'].fillna(value='No Features listed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4af0f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Sub Category            0\n",
      "Price                   3\n",
      "Discount                0\n",
      "Rating                  0\n",
      "Title                   0\n",
      "Currency                5\n",
      "Feature                 0\n",
      "Product Description    42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = grocery_df.isna().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47daada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default axis = 0, how= 'any'. Drops all rows where any columns is missing\n",
    "grocery_df['Price'].dropna()\n",
    "\n",
    "# If you want it to be checked only for certain columns, use subset.\n",
    "# Drops the rows where any of column1 or column2 value is missing.\n",
    "grocery_df.dropna(subset=['Currency', 'Product Description'], how = 'any', inplace=True)\n",
    "\n",
    "# Drops column, if any one of the column value is missing, not recommended.\n",
    "# grocery_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "513baa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Sub Category           0\n",
      "Price                  0\n",
      "Discount               0\n",
      "Rating                 0\n",
      "Title                  0\n",
      "Currency               0\n",
      "Feature                0\n",
      "Product Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = grocery_df.isna().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fa735",
   "metadata": {},
   "source": [
    "#### 2. Removing Duplicates\n",
    "Duplicate rows can skew your analysis results. Pandas offers a simple way to remove duplicates:\n",
    "\n",
    "* .duplicated(): This method identifies duplicate rows in a DataFrame.\n",
    "\n",
    "1. By Default duplicated, uses keep='first’ , which keeps the first observed row in the dataframe and marks the later observed ones as True, which specifies they are duplicated ones.\n",
    "2. If you want to keep the last observed duplicated row in the dataframe then you can give keep='last' .\n",
    "3. If you want to see all the duplicates, then you can give keep='False'\n",
    "4. If you want to check duplicates based on specific columns, then you need to give\n",
    "\n",
    "* .drop_duplicates(): Use this method to remove duplicate rows from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52d3b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>Paper &amp; Plastic Products</td>\n",
       "      <td>$16.19</td>\n",
       "      <td>After $3.80 OFF</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack</td>\n",
       "      <td>$</td>\n",
       "      <td>Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags</td>\n",
       "      <td>4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>Paper &amp; Plastic Products</td>\n",
       "      <td>$16.19</td>\n",
       "      <td>After $3.80 OFF</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack</td>\n",
       "      <td>$</td>\n",
       "      <td>Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags</td>\n",
       "      <td>4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>Paper &amp; Plastic Products</td>\n",
       "      <td>$16.19</td>\n",
       "      <td>After $3.80 OFF</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack</td>\n",
       "      <td>$</td>\n",
       "      <td>Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags</td>\n",
       "      <td>4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sub Category    Price         Discount     Rating  \\\n",
       "1344  Paper & Plastic Products  $16.19   After $3.80 OFF  No Rating   \n",
       "1345  Paper & Plastic Products  $16.19   After $3.80 OFF  No Rating   \n",
       "1346  Paper & Plastic Products  $16.19   After $3.80 OFF  No Rating   \n",
       "\n",
       "                                                      Title Currency  \\\n",
       "1344  Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack        $   \n",
       "1345  Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack        $   \n",
       "1346  Ziploc Seal Top Freezer Bag, Gallon, 38-count, 4-pack        $   \n",
       "\n",
       "                                                                                 Feature  \\\n",
       "1344  Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags   \n",
       "1345  Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags   \n",
       "1346  Seal Top Bags   1-Gallon Freezer Bags   38 Bags per Box   4 Boxes   152 Total Bags   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Product Description  \n",
       "1344  4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.  \n",
       "1345  4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.  \n",
       "1346  4 - 38 Count Boxes\\n152 Gallon Freezer Bags Total\\nFeaturing Easy Open Tabs\\nDesigned to protect food against freezer burn\\nSmart Zip Plus seal lets you feel, hear and see the bag close from edge-to-edge\\nHelps to preserve original flavor\\nMicrowave safe (use as directed). When defrosting and reheating, open zipper one inch to vent\\nCaution: When using in microwave, place bag on a microwave-safe dish. Handle with care. Bag and contents may be hot. Do not overheat contents as bag may melt.   Warning:\\nTo avoid danger of suffocation, keep bags away from babies and young children.  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results the duplicated columns \n",
    "# when there is an any other row with exact match of all the columns.\n",
    "duplicates = grocery_df[grocery_df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da85b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before removing duplicates, shape: (1712, 8)\n",
      "After removing duplicates, shape: (1709, 8)\n"
     ]
    }
   ],
   "source": [
    "# Identifying and removing duplicate rows based on all columns\n",
    "print(\"\\nBefore removing duplicates, shape:\", grocery_df.shape)\n",
    "grocery_df.drop_duplicates(inplace=True)\n",
    "print(\"After removing duplicates, shape:\", grocery_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103883ee",
   "metadata": {},
   "source": [
    "#### 3. String Operations\n",
    "\n",
    "When working with text data, Pandas offers string operations through .str an accessor to apply for the entire column which is of object data type.\n",
    "\n",
    "* .str.lower() and .str.upper(): These methods convert strings to lowercase or uppercase for the entire column values.\n",
    "* .str.replace(): Use this method to replace substrings within strings.\n",
    "* .str.contains() : This method allows you to check if a specific substring or pattern exists within a string. It returns a boolean Series indicating whether each element contains the specified pattern.\n",
    "* .str.slice(): You can extract a substring from each string in a Series using the .str.slice() method. Specify the start and end positions to define the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77f85fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>david’s cookies mile high peanut butter cake, 6.8 lbs (14 servings)</td>\n",
       "      <td>$56.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the cake bake shop 8\" round carrot cake (16-22 servings)</td>\n",
       "      <td>$159.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st michel madeleine, classic french sponge cake 100 - count</td>\n",
       "      <td>$44.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david’s cookies premier chocolate cake, 7.2 lbs (serves 14)</td>\n",
       "      <td>$59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>david's cookies mango &amp; strawberry cheesecake 2-count (28 slices total)</td>\n",
       "      <td>$59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>david's cookies no sugar added cheesecake &amp; marble truffle cake, 2-pack (28 slices total)</td>\n",
       "      <td>$59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the cake bake shop 8\" round chocolate cake (16-22 servings)</td>\n",
       "      <td>$159.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>david's cookies 10\" rainbow cake  (12 servings)</td>\n",
       "      <td>$62.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the cake bake shop 2 tier special occasion cake (16-22 servings)</td>\n",
       "      <td>$299.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>david's cookies chocolate fudge birthday cake, 3.75 lbs.  includes party pack (16 servings)</td>\n",
       "      <td>$54.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          Title  \\\n",
       "0                           david’s cookies mile high peanut butter cake, 6.8 lbs (14 servings)   \n",
       "1                                      the cake bake shop 8\" round carrot cake (16-22 servings)   \n",
       "2                                   st michel madeleine, classic french sponge cake 100 - count   \n",
       "4                                   david’s cookies premier chocolate cake, 7.2 lbs (serves 14)   \n",
       "5                       david's cookies mango & strawberry cheesecake 2-count (28 slices total)   \n",
       "7     david's cookies no sugar added cheesecake & marble truffle cake, 2-pack (28 slices total)   \n",
       "9                                   the cake bake shop 8\" round chocolate cake (16-22 servings)   \n",
       "10                                              david's cookies 10\" rainbow cake  (12 servings)   \n",
       "11                             the cake bake shop 2 tier special occasion cake (16-22 servings)   \n",
       "13  david's cookies chocolate fudge birthday cake, 3.75 lbs.  includes party pack (16 servings)   \n",
       "\n",
       "       Price  \n",
       "0    $56.99   \n",
       "1   $159.99   \n",
       "2    $44.99   \n",
       "4    $59.99   \n",
       "5    $59.99   \n",
       "7    $59.99   \n",
       "9   $159.99   \n",
       "10   $62.99   \n",
       "11  $299.99   \n",
       "13   $54.99   "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting 'Title' to lowercase for uniformity\n",
    "grocery_df['Title'] = grocery_df['Title'].str.lower()\n",
    "\n",
    "# Using .str.contains() to filter items with 'cake' in the title\n",
    "cake_items = grocery_df[grocery_df['Title'].str.contains('cake')]\n",
    "\n",
    "# Displaying a summary of 'cake' items\n",
    "cake_items[['Title', 'Price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167aa0d",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "\n",
    "Data manipulation is a core task in data analysis and involves transforming and modifying your data to derive insights or prepare it for further analysis. Pandas provides a rich set of methods for data manipulation that empower you to shape your data to meet your specific needs.\n",
    "\n",
    "#### 1. Applying Functions to DataFrames\n",
    "There is one hack to do element-wise operations for the dataframe using python .iterrows(). However, it’s important to note that Pandas is optimized for vectorized operations, and iterating through a DataFrame row by row is generally not the most efficient way to work with data in Pandas. It’s recommended to use vectorized operations whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37b24b",
   "metadata": {},
   "source": [
    "As an efficient way you can below functions to columns or rows of a DataFrame to perform element-wise operations:\n",
    "\n",
    "* .apply(): Use this method to apply a custom function to a series or to the entire dataframe.\n",
    "* -- when you use this on series, Each element of the original column will be passed to the function.\n",
    "* -- when you use this for the entire dataframe, based on the axis (1 - row, 0-column), the entire row or the entire column will be passed to the function.\n",
    "* .map(): This method applies a function to each element of a Series. It's particularly useful for transforming one column based on values from another.\n",
    "* .applymap(): When you want to apply a function to each element in the entire DataFrame, you can use .applymap()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5c9bee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discount\n",
       "No Discount                     1588\n",
       "After $6 OFF                      13\n",
       "After $5 OFF                      12\n",
       "After $4 OFF                      12\n",
       "After $3 OFF                       9\n",
       "After $3.30 OFF                    7\n",
       "After $3.60 OFF                    6\n",
       "After $20 OFF                      4\n",
       "After $50 OFF                      4\n",
       "After $30 OFF                      4\n",
       "After $3.80 OFF                    4\n",
       "After $3.50 OFF                    4\n",
       "After $3.10 OFF                    3\n",
       "After $60 OFF                      3\n",
       "After $10 OFF                      3\n",
       "After $2.20 OFF                    3\n",
       "After $12 OFF                      2\n",
       "After $5.60 OFF                    2\n",
       "After $2.50 OFF                    2\n",
       "After $70 OFF                      2\n",
       "After $2.30 OFF                    2\n",
       "After $40 OFF                      2\n",
       "After $2.60 OFF                    1\n",
       "After $7 OFF                       1\n",
       "After $4.10 OFF                    1\n",
       "After $2 OFF                       1\n",
       "After $6.50 OFF                    1\n",
       "Limit 5 Per Member                 1\n",
       "Limit 1 Per Member                 1\n",
       "After $9.30 OFF                    1\n",
       "After $80 OFF                      1\n",
       "After $40 - $70 OFF                1\n",
       "After $40 - $80 OFF                1\n",
       "After $2.70 OFF                    1\n",
       "After $1.50 OFF                    1\n",
       "After $8 OFF                       1\n",
       "After $2.80 OFF                    1\n",
       "After $4.50 OFF                    1\n",
       "This item is not returnable.       1\n",
       "After $2.40 OFF                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df['Discount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f07e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract discount value\n",
    "def extract_discount_value(discount):\n",
    "    if 'OFF' in discount:\n",
    "        # Assuming the discount format is 'After $X OFF'\n",
    "        return float(discount.split('$')[1].split()[0])\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Use .apply() to update the 'Discount' column\n",
    "grocery_df['Discount Value'] = grocery_df['Discount'].apply(extract_discount_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b82ed21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discount Value\n",
       "0.0     1591\n",
       "6.0       13\n",
       "5.0       12\n",
       "4.0       12\n",
       "3.0        9\n",
       "3.3        7\n",
       "3.6        6\n",
       "3.8        4\n",
       "40.0       4\n",
       "50.0       4\n",
       "30.0       4\n",
       "3.5        4\n",
       "20.0       4\n",
       "3.1        3\n",
       "10.0       3\n",
       "60.0       3\n",
       "2.2        3\n",
       "12.0       2\n",
       "5.6        2\n",
       "2.5        2\n",
       "70.0       2\n",
       "2.3        2\n",
       "7.0        1\n",
       "6.5        1\n",
       "4.1        1\n",
       "2.6        1\n",
       "2.0        1\n",
       "2.7        1\n",
       "80.0       1\n",
       "9.3        1\n",
       "1.5        1\n",
       "8.0        1\n",
       "2.8        1\n",
       "4.5        1\n",
       "2.4        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df['Discount Value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a6bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping function for discount categories\n",
    "def discount_category(discount):\n",
    "    if discount >= 10.0:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "# Use .map() to apply the categorization\n",
    "grocery_df['Discount Category'] = grocery_df['Discount Value'].map(discount_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "056a7127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discount Category\n",
       "Low     1682\n",
       "High      27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df['Discount Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1864f2",
   "metadata": {},
   "source": [
    "In Pandas, the lambda function is often used in conjunction with .apply(), .map(), .applymap(), and other similar methods for inline, anonymous function definitions. This approach is particularly useful for applying quick, one-off functions to DataFrame or Series objects without the need to formally define a separate function.\n",
    "\n",
    "* lambda Function: A lambda function is a small anonymous function in Python. It can take any number of arguments, but can only have one expression. The syntax is lambda arguments: expression. The expression is executed and the result is returned.\n",
    "\n",
    "* Usage with .apply(): When you use a lambda function with .apply(), it allows you to apply a simple function to each element (when used on a Series) or to each row/column (when used on a DataFrame) without defining a traditional function using def.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "068c6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/q2977b1d2f11wv63sxv4cyhh0000gn/T/ipykernel_60878/2592007138.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  grocery_df[['Title', 'Feature']] = text_columns.applymap(lambda x: x.upper())\n"
     ]
    }
   ],
   "source": [
    "# Selecting only the columns we want to modify\n",
    "text_columns = grocery_df[['Title', 'Feature']]\n",
    "\n",
    "# Use .applymap() to convert all text to uppercase\n",
    "grocery_df[['Title', 'Feature']] = text_columns.applymap(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fa08db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Discount Value</th>\n",
       "      <th>Discount Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$56.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.3 out of 5 stars based on 265 reviews.</td>\n",
       "      <td>DAVID’S COOKIES MILE HIGH PEANUT BUTTER CAKE, 6.8 LBS (14 SERVINGS)</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\"\" PEANUT BUTTER CAKE\\nCERTIFIED KOSHER OU-D\\n14 SERVINGS</td>\n",
       "      <td>A cake the dessert epicure will die for!Our Top Selling Cake! Fudge brownie base, layered in velvety smooth peanut butter mousse, rich chocolate cake, topped with brownie chunks, handful of peanut butter chips, drizzled in fudge. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. -\\tGenerously sized precut slices, a cake lover’s dreams come true! Includes:Measures 10” diameterWeighs in at 6.8 lbs.14 servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$159.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 5 out of 5 stars based on 1 reviews.</td>\n",
       "      <td>THE CAKE BAKE SHOP 8\" ROUND CARROT CAKE (16-22 SERVINGS)</td>\n",
       "      <td>$</td>\n",
       "      <td>SPICED CARROT CAKE WITH CREAM CHEESE FROSTING   SILK CHERRY BLOSSOM FLOWERS (NOT EDIBLE)   NO NUTS OR RAISINS   DIMENSIONS: 9” DIAMETER, 7” HIGH   16-22 SERVINGS</td>\n",
       "      <td>Due to the perishable nature of this item, orders do NOT ship over the weekend. Orders can only be delivered on Wednesday, Thursday and Friday. Minimum delivery time is 5 business days.   Plate not included.   Gwendolyn Rogers' The Cake Bake Shop is famous for handcrafting magnificent and delicious cakes and desserts for her award winning restaurants. Each cake arrives beautifully packaged in her bakery’s signature pink and gold cake box with a pink satin ribbon and is topped with the bakery’s dusting of edible Pixie Glitter®, adding a sparkling finish to every dessert. Gwendolyn’s moist and delicious carrot cake is made with hand peeled and freshly grated carrots. Perfectly spiced with just the right amount of cinnamon, this cake has no nuts and no raisins. The three layers of spiced carrot cake are then filled and frosted with Gwendolyn's signature homemade cream cheese frosting. Topped with decorative pink silk cherry blossom flowers.   Features:   Flavor: Spiced Carrot Cake\\nCake Filling: Cream Cheese Frosting\\nCake Frosting: Cream Cheese Frosting\\nTopped with Pink Silk Cherry Blossom Flowers (cherry blossom flowers are not edible, please do not consume, remove before eating)\\nDimensions: 9” diameter, 7” high\\nServes 16-22\\nEach Cake Arrives With It’s Own Cake Care Card\\nAllergens: Contains Wheat, Milk, Soy, Egg\\nShips Frozen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$44.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.1 out of 5 stars based on 441 reviews.</td>\n",
       "      <td>ST MICHEL MADELEINE, CLASSIC FRENCH SPONGE CAKE 100 - COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>100 COUNT\\nINDIVIDUALLY WRAPPED\\nMADE IN AND IMPORTED FROM FRANCE\\nFREE-RANGE EGGS\\nNON-GMO INGREDIENTS</td>\n",
       "      <td>Moist and buttery sponge cakes with the traditional European madeleine flavor of almond. The Classic Madeleine is baked in the shape of seashell with ridges on one side and a “belly” on the other. Each madeleine is individually-wrapped for portion control and convenience.The Origin of the Madeleine: 18th century King Stanislas 1st, Duke of Lorraine During a festive dinner party in Commercy, France, the king’s chef abruptly left the kitchen. Seeking a solution to feed his guests dessert, a servant girl in the kitchen offered to make her family’s traditional pastry. The king enjoyed the little cake so much that he named it after the servant: Madeleine. Baked with non-GMO ingredients and free-range eggs. No preservatives, palm oil, hydrogenated oil or colorings. Baked with love in France.We all have our Madeleine moment:Enjoy everyday for breakfast, snack or dessert (Just as the French do!)Pack in lunches or backpacks for schoolServe during business, book club or PTA meetingsCut in half and fill with jelly or chocolate hazelnut spreadDecorate cakes or cupcakes with classic seashell shapeIncludes:100 countIndividually wrappedFree-range eggsNon-GMO ingredients</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$39.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.7 out of 5 stars based on 9459 reviews.</td>\n",
       "      <td>DAVID'S COOKIES BUTTER PECAN MELTAWAYS 32 OZ, 2-PACK</td>\n",
       "      <td>$</td>\n",
       "      <td>BUTTER PECAN MELTAWAYS\\n32 OZ 2-PACK\\nNO PRESERVATIVES\\nCERTIFIED KOSHER OU-D\\nCONTAINS NUTS</td>\n",
       "      <td>These delectable butter pecan meltaways are the perfect snack or dessert for the whole family. The treats are made with pure creamy butter and large pecan chunks and have just the right amount of powdered sugar to satisfy your sweet tooth.Includes:Includes: 2 Tins (32 oz. each)Contains nutsNo preservativesEnjoy with your morning coffee or teaCookies can be stored at room temperature for up to 60 daysEach tin contains approximately 64 cookiesKosher OU-DSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.5 out of 5 stars based on 758 reviews.</td>\n",
       "      <td>DAVID’S COOKIES PREMIER CHOCOLATE CAKE, 7.2 LBS (SERVES 14)</td>\n",
       "      <td>$</td>\n",
       "      <td>\"10\" FOUR LAYER CHOCOLATE CAKE\\nCERTIFIED KOSHER OU-D\\nSERVES 14</td>\n",
       "      <td>A cake the dessert epicure will die for!To the ultimate chocolate lover - We've baked your dream cake! Four split layers of our rich chocolate cake, filled with a smooth milk chocolate mousse, finished in chocolate ganache &amp; covered in dark chocolate bark pieces. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. Generously sized precut slices, A cake lover’s dreams come true! Includes:1 - 10” Premier Chocolate Overload CakeWeighs in at 7.2 lbs.14 Servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$23.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>OBERTO THIN STYLE SMOKED SAUSAGE STICK, COCKTAIL PEPPERONI, 3 OZ, 8-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>COCKTAIL PEPPERONI   SMOKED SAUSAGE STICKS   3 OZ BAG   8-COUNT   NET WEIGHT: 24 OZ</td>\n",
       "      <td>Cocktail PepperoniSmoked Sausage Sticks3 oz bag8-count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$49.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>CHEETOS CRUNCHY, ORIGINAL, 2.1 OZ, 64-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>MADE WITH REAL CHEESE</td>\n",
       "      <td>64-count2.1 oz Bags</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$22.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>SABRITAS CHILE &amp; LIMON MIX, VARIETY PACK, 30-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>CHILE &amp; LIMÓN MIX   VARIETY PACK   30 CT   NET WEIGHT 48 OZ</td>\n",
       "      <td>8-Doritos Dinamita Chile Limón Flavored Rolled Tortilla Chips (1.75 oz bag)\\n8-Lay's Limón Flavored Potato Chips (1.5 oz bag)\\n6-Sabritones Chile &amp; Lime Flavored Puffed Wheat Snacks (1.0 oz bag)\\n8-Sabritas Turbo Flamas Flavored Corn Snacks (2.0 oz bag)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$17.49</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>FRUIT ROLL-UPS, VARIETY PACK, 72-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>VARIETY PACK   1   BOX WITH 72 ROLLS   FLAVORED WITH OTHER NATURAL FLAVORS   GELATIN AND GLUTEN FREE</td>\n",
       "      <td>Fruit Flavored Snacks\\nVariety Includes: Strawberry Blast, Tropical Tie Dye\\nIndividually Wrapped\\nTotal Net Weight 2.3 lbs.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$21.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>TAKIS, ROLLED TORTILLA CHIPS, INTENSE NACHO, 1 OZ, 50-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>INTENSE NACHO CHEESE   NON-SPICY   1 OZ BAG, 50 COUNT   ARTIFICIALLY FLAVORED</td>\n",
       "      <td>Takis Non-Spicy Cheese Tortilla Chips\\nIndividually Packaged\\n50-count\\nKeep in a Cool Dry Place</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1709 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sub Category     Price     Discount  \\\n",
       "0     Bakery & Desserts   $56.99   No Discount   \n",
       "1     Bakery & Desserts  $159.99   No Discount   \n",
       "2     Bakery & Desserts   $44.99   No Discount   \n",
       "3     Bakery & Desserts   $39.99   No Discount   \n",
       "4     Bakery & Desserts   $59.99   No Discount   \n",
       "...                 ...       ...          ...   \n",
       "1752             Snacks   $23.99   No Discount   \n",
       "1753             Snacks   $49.99   No Discount   \n",
       "1754             Snacks   $22.99   No Discount   \n",
       "1755             Snacks   $17.49   No Discount   \n",
       "1756             Snacks   $21.99   No Discount   \n",
       "\n",
       "                                               Rating  \\\n",
       "0      Rated 4.3 out of 5 stars based on 265 reviews.   \n",
       "1          Rated 5 out of 5 stars based on 1 reviews.   \n",
       "2      Rated 4.1 out of 5 stars based on 441 reviews.   \n",
       "3     Rated 4.7 out of 5 stars based on 9459 reviews.   \n",
       "4      Rated 4.5 out of 5 stars based on 758 reviews.   \n",
       "...                                               ...   \n",
       "1752                                        No Rating   \n",
       "1753                                        No Rating   \n",
       "1754                                        No Rating   \n",
       "1755                                        No Rating   \n",
       "1756                                        No Rating   \n",
       "\n",
       "                                                                          Title  \\\n",
       "0           DAVID’S COOKIES MILE HIGH PEANUT BUTTER CAKE, 6.8 LBS (14 SERVINGS)   \n",
       "1                      THE CAKE BAKE SHOP 8\" ROUND CARROT CAKE (16-22 SERVINGS)   \n",
       "2                   ST MICHEL MADELEINE, CLASSIC FRENCH SPONGE CAKE 100 - COUNT   \n",
       "3                          DAVID'S COOKIES BUTTER PECAN MELTAWAYS 32 OZ, 2-PACK   \n",
       "4                   DAVID’S COOKIES PREMIER CHOCOLATE CAKE, 7.2 LBS (SERVES 14)   \n",
       "...                                                                         ...   \n",
       "1752  OBERTO THIN STYLE SMOKED SAUSAGE STICK, COCKTAIL PEPPERONI, 3 OZ, 8-COUNT   \n",
       "1753                                CHEETOS CRUNCHY, ORIGINAL, 2.1 OZ, 64-COUNT   \n",
       "1754                         SABRITAS CHILE & LIMON MIX, VARIETY PACK, 30-COUNT   \n",
       "1755                                     FRUIT ROLL-UPS, VARIETY PACK, 72-COUNT   \n",
       "1756                TAKIS, ROLLED TORTILLA CHIPS, INTENSE NACHO, 1 OZ, 50-COUNT   \n",
       "\n",
       "     Currency  \\\n",
       "0           $   \n",
       "1           $   \n",
       "2           $   \n",
       "3           $   \n",
       "4           $   \n",
       "...       ...   \n",
       "1752        $   \n",
       "1753        $   \n",
       "1754        $   \n",
       "1755        $   \n",
       "1756        $   \n",
       "\n",
       "                                                                                                                                                                Feature  \\\n",
       "0                                                                                                          \"10\"\" PEANUT BUTTER CAKE\\nCERTIFIED KOSHER OU-D\\n14 SERVINGS   \n",
       "1     SPICED CARROT CAKE WITH CREAM CHEESE FROSTING   SILK CHERRY BLOSSOM FLOWERS (NOT EDIBLE)   NO NUTS OR RAISINS   DIMENSIONS: 9” DIAMETER, 7” HIGH   16-22 SERVINGS   \n",
       "2                                                               100 COUNT\\nINDIVIDUALLY WRAPPED\\nMADE IN AND IMPORTED FROM FRANCE\\nFREE-RANGE EGGS\\nNON-GMO INGREDIENTS   \n",
       "3                                                                          BUTTER PECAN MELTAWAYS\\n32 OZ 2-PACK\\nNO PRESERVATIVES\\nCERTIFIED KOSHER OU-D\\nCONTAINS NUTS   \n",
       "4                                                                                                      \"10\" FOUR LAYER CHOCOLATE CAKE\\nCERTIFIED KOSHER OU-D\\nSERVES 14   \n",
       "...                                                                                                                                                                 ...   \n",
       "1752                                                                                COCKTAIL PEPPERONI   SMOKED SAUSAGE STICKS   3 OZ BAG   8-COUNT   NET WEIGHT: 24 OZ   \n",
       "1753                                                                                                                                              MADE WITH REAL CHEESE   \n",
       "1754                                                                                                        CHILE & LIMÓN MIX   VARIETY PACK   30 CT   NET WEIGHT 48 OZ   \n",
       "1755                                                               VARIETY PACK   1   BOX WITH 72 ROLLS   FLAVORED WITH OTHER NATURAL FLAVORS   GELATIN AND GLUTEN FREE   \n",
       "1756                                                                                      INTENSE NACHO CHEESE   NON-SPICY   1 OZ BAG, 50 COUNT   ARTIFICIALLY FLAVORED   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Product Description  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               A cake the dessert epicure will die for!Our Top Selling Cake! Fudge brownie base, layered in velvety smooth peanut butter mousse, rich chocolate cake, topped with brownie chunks, handful of peanut butter chips, drizzled in fudge. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. -\\tGenerously sized precut slices, a cake lover’s dreams come true! Includes:Measures 10” diameterWeighs in at 6.8 lbs.14 servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils   \n",
       "1     Due to the perishable nature of this item, orders do NOT ship over the weekend. Orders can only be delivered on Wednesday, Thursday and Friday. Minimum delivery time is 5 business days.   Plate not included.   Gwendolyn Rogers' The Cake Bake Shop is famous for handcrafting magnificent and delicious cakes and desserts for her award winning restaurants. Each cake arrives beautifully packaged in her bakery’s signature pink and gold cake box with a pink satin ribbon and is topped with the bakery’s dusting of edible Pixie Glitter®, adding a sparkling finish to every dessert. Gwendolyn’s moist and delicious carrot cake is made with hand peeled and freshly grated carrots. Perfectly spiced with just the right amount of cinnamon, this cake has no nuts and no raisins. The three layers of spiced carrot cake are then filled and frosted with Gwendolyn's signature homemade cream cheese frosting. Topped with decorative pink silk cherry blossom flowers.   Features:   Flavor: Spiced Carrot Cake\\nCake Filling: Cream Cheese Frosting\\nCake Frosting: Cream Cheese Frosting\\nTopped with Pink Silk Cherry Blossom Flowers (cherry blossom flowers are not edible, please do not consume, remove before eating)\\nDimensions: 9” diameter, 7” high\\nServes 16-22\\nEach Cake Arrives With It’s Own Cake Care Card\\nAllergens: Contains Wheat, Milk, Soy, Egg\\nShips Frozen   \n",
       "2                                                                                                                                                                                       Moist and buttery sponge cakes with the traditional European madeleine flavor of almond. The Classic Madeleine is baked in the shape of seashell with ridges on one side and a “belly” on the other. Each madeleine is individually-wrapped for portion control and convenience.The Origin of the Madeleine: 18th century King Stanislas 1st, Duke of Lorraine During a festive dinner party in Commercy, France, the king’s chef abruptly left the kitchen. Seeking a solution to feed his guests dessert, a servant girl in the kitchen offered to make her family’s traditional pastry. The king enjoyed the little cake so much that he named it after the servant: Madeleine. Baked with non-GMO ingredients and free-range eggs. No preservatives, palm oil, hydrogenated oil or colorings. Baked with love in France.We all have our Madeleine moment:Enjoy everyday for breakfast, snack or dessert (Just as the French do!)Pack in lunches or backpacks for schoolServe during business, book club or PTA meetingsCut in half and fill with jelly or chocolate hazelnut spreadDecorate cakes or cupcakes with classic seashell shapeIncludes:100 countIndividually wrappedFree-range eggsNon-GMO ingredients   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       These delectable butter pecan meltaways are the perfect snack or dessert for the whole family. The treats are made with pure creamy butter and large pecan chunks and have just the right amount of powdered sugar to satisfy your sweet tooth.Includes:Includes: 2 Tins (32 oz. each)Contains nutsNo preservativesEnjoy with your morning coffee or teaCookies can be stored at room temperature for up to 60 daysEach tin contains approximately 64 cookiesKosher OU-DSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              A cake the dessert epicure will die for!To the ultimate chocolate lover - We've baked your dream cake! Four split layers of our rich chocolate cake, filled with a smooth milk chocolate mousse, finished in chocolate ganache & covered in dark chocolate bark pieces. This cake is the thoughtful gift idea that’s perfect for family, friends, coworkers, or to anyone you care about in your life. Generously sized precut slices, A cake lover’s dreams come true! Includes:1 - 10” Premier Chocolate Overload CakeWeighs in at 7.2 lbs.14 Servings OU-D certified, the most trusted kosher certification in the U.S.All natural with no added preservativesSome of our products may contain nuts. Our facility is NOT a nut-free facility, and as a result it is possible that any product may have come in contact with nut or nut oils   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "1752                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Cocktail PepperoniSmoked Sausage Sticks3 oz bag8-count   \n",
       "1753                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      64-count2.1 oz Bags   \n",
       "1754                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            8-Doritos Dinamita Chile Limón Flavored Rolled Tortilla Chips (1.75 oz bag)\\n8-Lay's Limón Flavored Potato Chips (1.5 oz bag)\\n6-Sabritones Chile & Lime Flavored Puffed Wheat Snacks (1.0 oz bag)\\n8-Sabritas Turbo Flamas Flavored Corn Snacks (2.0 oz bag)   \n",
       "1755                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Fruit Flavored Snacks\\nVariety Includes: Strawberry Blast, Tropical Tie Dye\\nIndividually Wrapped\\nTotal Net Weight 2.3 lbs.   \n",
       "1756                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Takis Non-Spicy Cheese Tortilla Chips\\nIndividually Packaged\\n50-count\\nKeep in a Cool Dry Place   \n",
       "\n",
       "      Discount Value Discount Category  \n",
       "0                0.0               Low  \n",
       "1                0.0               Low  \n",
       "2                0.0               Low  \n",
       "3                0.0               Low  \n",
       "4                0.0               Low  \n",
       "...              ...               ...  \n",
       "1752             0.0               Low  \n",
       "1753             0.0               Low  \n",
       "1754             0.0               Low  \n",
       "1755             0.0               Low  \n",
       "1756             0.0               Low  \n",
       "\n",
       "[1709 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f98866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Discount Given: $1390.999999999999\n"
     ]
    }
   ],
   "source": [
    "total_discount = 0\n",
    "for index, row in grocery_df.iterrows():\n",
    "    if row['Discount Value'] > 0:\n",
    "        total_discount += row['Discount Value']\n",
    "\n",
    "print(f\"Total Discount Given: ${total_discount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5acc696",
   "metadata": {},
   "source": [
    "#### 2. Adding and Removing Columns\n",
    "\n",
    "You can add and remove columns to tailor your DataFrame for analysis:\n",
    "\n",
    "* Adding Columns: To add a new column or replace an existing one, simply assign values to it.\n",
    "* Removing Columns: Use the .drop() method to remove columns. Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’). You can use axis=1/ ‘columns’ to drop column, or use axis =0/ ‘index’ to drop the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23d16b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column 'Is Bakery Item'\n",
    "grocery_df['Is Bakery Item'] = grocery_df['Sub Category'].apply(lambda x: x == 'Bakery & Desserts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb34df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Feature' and 'Product Description' columns\n",
    "grocery_df.drop(['Feature', 'Product Description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f8fa70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Discount Value</th>\n",
       "      <th>Discount Category</th>\n",
       "      <th>Is Bakery Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$56.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.3 out of 5 stars based on 265 reviews.</td>\n",
       "      <td>DAVID’S COOKIES MILE HIGH PEANUT BUTTER CAKE, 6.8 LBS (14 SERVINGS)</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$159.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 5 out of 5 stars based on 1 reviews.</td>\n",
       "      <td>THE CAKE BAKE SHOP 8\" ROUND CARROT CAKE (16-22 SERVINGS)</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$44.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.1 out of 5 stars based on 441 reviews.</td>\n",
       "      <td>ST MICHEL MADELEINE, CLASSIC FRENCH SPONGE CAKE 100 - COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$39.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.7 out of 5 stars based on 9459 reviews.</td>\n",
       "      <td>DAVID'S COOKIES BUTTER PECAN MELTAWAYS 32 OZ, 2-PACK</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bakery &amp; Desserts</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>Rated 4.5 out of 5 stars based on 758 reviews.</td>\n",
       "      <td>DAVID’S COOKIES PREMIER CHOCOLATE CAKE, 7.2 LBS (SERVES 14)</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$23.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>OBERTO THIN STYLE SMOKED SAUSAGE STICK, COCKTAIL PEPPERONI, 3 OZ, 8-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$49.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>CHEETOS CRUNCHY, ORIGINAL, 2.1 OZ, 64-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$22.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>SABRITAS CHILE &amp; LIMON MIX, VARIETY PACK, 30-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$17.49</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>FRUIT ROLL-UPS, VARIETY PACK, 72-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>$21.99</td>\n",
       "      <td>No Discount</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>TAKIS, ROLLED TORTILLA CHIPS, INTENSE NACHO, 1 OZ, 50-COUNT</td>\n",
       "      <td>$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1709 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sub Category     Price     Discount  \\\n",
       "0     Bakery & Desserts   $56.99   No Discount   \n",
       "1     Bakery & Desserts  $159.99   No Discount   \n",
       "2     Bakery & Desserts   $44.99   No Discount   \n",
       "3     Bakery & Desserts   $39.99   No Discount   \n",
       "4     Bakery & Desserts   $59.99   No Discount   \n",
       "...                 ...       ...          ...   \n",
       "1752             Snacks   $23.99   No Discount   \n",
       "1753             Snacks   $49.99   No Discount   \n",
       "1754             Snacks   $22.99   No Discount   \n",
       "1755             Snacks   $17.49   No Discount   \n",
       "1756             Snacks   $21.99   No Discount   \n",
       "\n",
       "                                               Rating  \\\n",
       "0      Rated 4.3 out of 5 stars based on 265 reviews.   \n",
       "1          Rated 5 out of 5 stars based on 1 reviews.   \n",
       "2      Rated 4.1 out of 5 stars based on 441 reviews.   \n",
       "3     Rated 4.7 out of 5 stars based on 9459 reviews.   \n",
       "4      Rated 4.5 out of 5 stars based on 758 reviews.   \n",
       "...                                               ...   \n",
       "1752                                        No Rating   \n",
       "1753                                        No Rating   \n",
       "1754                                        No Rating   \n",
       "1755                                        No Rating   \n",
       "1756                                        No Rating   \n",
       "\n",
       "                                                                          Title  \\\n",
       "0           DAVID’S COOKIES MILE HIGH PEANUT BUTTER CAKE, 6.8 LBS (14 SERVINGS)   \n",
       "1                      THE CAKE BAKE SHOP 8\" ROUND CARROT CAKE (16-22 SERVINGS)   \n",
       "2                   ST MICHEL MADELEINE, CLASSIC FRENCH SPONGE CAKE 100 - COUNT   \n",
       "3                          DAVID'S COOKIES BUTTER PECAN MELTAWAYS 32 OZ, 2-PACK   \n",
       "4                   DAVID’S COOKIES PREMIER CHOCOLATE CAKE, 7.2 LBS (SERVES 14)   \n",
       "...                                                                         ...   \n",
       "1752  OBERTO THIN STYLE SMOKED SAUSAGE STICK, COCKTAIL PEPPERONI, 3 OZ, 8-COUNT   \n",
       "1753                                CHEETOS CRUNCHY, ORIGINAL, 2.1 OZ, 64-COUNT   \n",
       "1754                         SABRITAS CHILE & LIMON MIX, VARIETY PACK, 30-COUNT   \n",
       "1755                                     FRUIT ROLL-UPS, VARIETY PACK, 72-COUNT   \n",
       "1756                TAKIS, ROLLED TORTILLA CHIPS, INTENSE NACHO, 1 OZ, 50-COUNT   \n",
       "\n",
       "     Currency  Discount Value Discount Category  Is Bakery Item  \n",
       "0           $             0.0               Low            True  \n",
       "1           $             0.0               Low            True  \n",
       "2           $             0.0               Low            True  \n",
       "3           $             0.0               Low            True  \n",
       "4           $             0.0               Low            True  \n",
       "...       ...             ...               ...             ...  \n",
       "1752        $             0.0               Low           False  \n",
       "1753        $             0.0               Low           False  \n",
       "1754        $             0.0               Low           False  \n",
       "1755        $             0.0               Low           False  \n",
       "1756        $             0.0               Low           False  \n",
       "\n",
       "[1709 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6cf9d",
   "metadata": {},
   "source": [
    "#### 3. Combining DataFrames (Concatenation, Joining, Merging)\n",
    "\n",
    "Pandas offers powerful methods to combine DataFrames:\n",
    "\n",
    "* Concatenation: You can concatenate DataFrames vertically or horizontally using pd.concat(). axis=0 will concatenate them in the rows, axis=1 will concatenate them in the columns. It will check for the common columns between both the dataframes and for the matched columns, it will concatenate in the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7c8af85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B    C    D\n",
       "0  1   4  1.0  NaN\n",
       "1  2   5  2.0  NaN\n",
       "2  3   6  3.0  NaN\n",
       "0  7  10  NaN  1.0\n",
       "1  8  11  NaN  2.0\n",
       "2  9  12  NaN  3.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrames with the same column names\n",
    "data1 = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C':[1,2,3]}\n",
    "data2 = {'A': [7, 8, 9], 'B': [10, 11, 12], 'D':[1,2,3]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Concatenate df1 and df2 horizontally (along columns) with same column names\n",
    "result = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "result\n",
    "\n",
    "# Tip: To make the index proper, you can use -> result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5fbbae",
   "metadata": {},
   "source": [
    "* Joining: You can perform SQL-like joins on DataFrames using the .merge() method.\n",
    "* Merging: Pandas allows you to merge DataFrames based on common columns. Using merge you can perform various joins such as inner, outer, left, and right.\n",
    "\n",
    "An inner join will only keep where the cells of common columns have matched.\n",
    "\n",
    "An outer join will keep every row from both data frames. Left will keep all the rows from the left table, similarly right for all the rows from the right table.\n",
    "\n",
    "If you want to match a table column with the index of another table, then for the table you want to match it with the index, specify left_index=True or right_index=True accordingly. And for the other table on which column you want to match it with, you have to specify it as left_on=column_name or right_on=column_name accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f2b86dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join\n",
      "   ID     Name  Age\n",
      "0   2      Bob   25\n",
      "1   3  Charlie   30\n",
      "Left Join\n",
      "   ID     Name   Age\n",
      "0   1    Alice   NaN\n",
      "1   2      Bob  25.0\n",
      "2   3  Charlie  30.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3, 4], 'Age': [25, 30, 22]})\n",
    "\n",
    "# Inner join on 'ID'\n",
    "result = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(\"Inner Join\")\n",
    "print(result)\n",
    "\n",
    "# Left join on 'ID'\n",
    "result = pd.merge(df1, df2, on='ID', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(\"Left Join\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d990a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If matching column names are different from both data frames\n",
    "# you can specify them manually\n",
    "# Considering, left table has ID1 and right table has ID2\n",
    "# pd.merge(df1,df2, left_on=\"ID1\", right_on=\"ID2\")\n",
    "\n",
    "# Here it will try to match the left dataframe index with right ID column\n",
    "# pd.merge(df1,df2, left_index=True,right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f79159",
   "metadata": {},
   "source": [
    "### Data Aggregations\n",
    "\n",
    "Meaningful insights will never be observed without proper aggregation of data, right? In fact, that’s why we use pivot tables a lot in excel. So we can say that it’s a critical step in data analysis and often involves applying aggregation functions like sum, mean, count, etc., to groups of data\n",
    "\n",
    "#### 1. Grouping Data\n",
    "\n",
    "* groupby with a single column: This method allows you to group data based on one or more columns. You can think of it as a powerful version of the SQL GROUP BY statement.\n",
    "\n",
    "First, you need to pass the column name on which you want to group the data, After that, you can use the grouped data and choose the column between which you want to compare this grouped data, and then select the aggregate function( mean, sum, max, min, etc.. ).\n",
    "\n",
    "When you apply an aggregation function to grouped data without specifying a column, it will be applied to all the numeric columns in the DataFrame.\n",
    "Eg: Let’s say you have sales data and you want to group it by the “Category” column and calculate the total sales within each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "badd9b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Clothing       1000\n",
       "Electronics    1800\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Category': ['Electronics', 'Clothing', 'Electronics', 'Clothing'],\n",
    "        'Sales': [1000, 500, 800, 500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Category'\n",
    "grouped_data = df.groupby('Category')\n",
    "\n",
    "# Choosing sales column to compare with grouped data and using sum function\n",
    "# This gives the total sales for each category.\n",
    "total_sales = grouped_data['Sales'].sum()\n",
    "\n",
    "total_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4a9eb",
   "metadata": {},
   "source": [
    "* groupby with multiple columns: You can even group with multiple columns by passing a list of columns you want to group by.\n",
    "\n",
    "Eg: Suppose you have a dataset with student information including their grades in different subjects, and you want to group the data by both “Class” and “Gender” columns, then calculate statistics such as the average, minimum, and maximum scores for Math subject score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d07af41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class  Gender\n",
       "A      Female    78.0\n",
       "       Male      87.5\n",
       "B      Female    87.5\n",
       "       Male      92.0\n",
       "Name: Math_Score, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Class': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'Gender': ['Male', 'Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "        'Math_Score': [85, 92, 78, 89, 90, 86],\n",
    "        'English_Score': [88, 94, 80, 92, 92, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Class' and 'Gender' and calculating statistics\n",
    "grouped_data = df.groupby(['Class', 'Gender'])\n",
    "\n",
    "# Calculate the mean for Math_score\n",
    "agg_results = grouped_data['Math_Score'].mean()\n",
    "\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8288a",
   "metadata": {},
   "source": [
    "* Apply aggregate function to grouped data without specifying a column:\n",
    "In such cases, it will be applied to all the numeric columns in the grouped DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0645fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Math_Score</th>\n",
       "      <th>English_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">A</th>\n",
       "      <th>Female</th>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>87.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>Female</th>\n",
       "      <td>87.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Math_Score  English_Score\n",
       "Class Gender                           \n",
       "A     Female        78.0           80.0\n",
       "      Male          87.5           90.0\n",
       "B     Female        87.5           90.0\n",
       "      Male          92.0           94.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Class': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'Gender': ['Male', 'Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "        'Math_Score': [85, 92, 78, 89, 90, 86],\n",
    "        'English_Score': [88, 94, 80, 92, 92, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Class' and 'Gender'\n",
    "grouped_data = df.groupby(['Class', 'Gender'])\n",
    "\n",
    "# Applying the mean aggregation function to all numeric columns\n",
    "aggregated_data = grouped_data.mean()\n",
    "\n",
    "aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631ee89",
   "metadata": {},
   "source": [
    "#### 2. Aggregation Functions\n",
    "\n",
    "Aggregation functions are essential for summarizing data within groups. And the Common Aggregation Functions are sum(), max(), min(), mean(), median(), count(), agg() — this allows you apply custom aggregation funcitons.\n",
    "\n",
    "Eg: Say you want to apply multiple aggregate functions ( mean, min, and max) at once for the Math Score. You also want to check these multiple aggregate functions for two subjects ( particularly a few columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08ef7a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">A</th>\n",
       "      <th>Female</th>\n",
       "      <td>78.0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>87.5</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>Female</th>\n",
       "      <td>87.5</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  min  max\n",
       "Class Gender                \n",
       "A     Female  78.0   78   78\n",
       "      Male    87.5   85   90\n",
       "B     Female  87.5   86   89\n",
       "      Male    92.0   92   92"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Class': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'Gender': ['Male', 'Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "        'Math_Score': [85, 92, 78, 89, 90, 86],\n",
    "        'English_Score': [88, 94, 80, 92, 92, 88],\n",
    "        'Physics_Score': [78, 90, 85, 92, 88, 84]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Class' and 'Gender' and calculating statistics\n",
    "grouped_data = df.groupby(['Class', 'Gender'])\n",
    "\n",
    "# Calculate the mean, min, and max scores for Math_score\n",
    "agg_results = grouped_data.Math_Score.agg(['mean', 'min', 'max'])\n",
    "\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afae01a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Math_Score</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Physics_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">A</th>\n",
       "      <th>Female</th>\n",
       "      <td>78.0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>87.5</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>Female</th>\n",
       "      <td>87.5</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Math_Score         Physics_Score        \n",
       "                   mean min max          mean min max\n",
       "Class Gender                                         \n",
       "A     Female       78.0  78  78          85.0  85  85\n",
       "      Male         87.5  85  90          83.0  78  88\n",
       "B     Female       87.5  86  89          88.0  84  92\n",
       "      Male         92.0  92  92          90.0  90  90"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying aggregation functions to 'Math_Score' and 'Physics_Score'\n",
    "aggregated_data = grouped_data.agg({\n",
    "    'Math_Score': ['mean', 'min', 'max'],\n",
    "    'Physics_Score': ['mean', 'min', 'max']\n",
    "})\n",
    "\n",
    "aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929702ec",
   "metadata": {},
   "source": [
    "### Case Study: Health Metrics Analysis\n",
    "\n",
    "#### Dataset Overview:\n",
    "* Patient ID: Unique identifier for each patient.\n",
    "* Age: Age of the patient.\n",
    "* Weight: Weight of the patient in kilograms.\n",
    "* Cholesterol Level: Cholesterol level in mg/dL.\n",
    "* Blood Pressure: Blood pressure reading (systolic/diastolic) in mmHg.\n",
    "* Date: Date of the health metric recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c055b080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Cholesterol Level</th>\n",
       "      <th>Blood Pressure Systolic</th>\n",
       "      <th>Blood Pressure Diastolic</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>75.666200</td>\n",
       "      <td>207</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>70.016888</td>\n",
       "      <td>171</td>\n",
       "      <td>139</td>\n",
       "      <td>74</td>\n",
       "      <td>2024-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>61.429007</td>\n",
       "      <td>238</td>\n",
       "      <td>139</td>\n",
       "      <td>88</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>84.289981</td>\n",
       "      <td>198</td>\n",
       "      <td>124</td>\n",
       "      <td>76</td>\n",
       "      <td>2024-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>57.538521</td>\n",
       "      <td>240</td>\n",
       "      <td>139</td>\n",
       "      <td>78</td>\n",
       "      <td>2024-05-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Age     Weight  Cholesterol Level  Blood Pressure Systolic  \\\n",
       "0           1   58  75.666200                207                      124   \n",
       "1           2   48  70.016888                171                      139   \n",
       "2           3   34  61.429007                238                      139   \n",
       "3           4   62  84.289981                198                      124   \n",
       "4           5   27  57.538521                240                      139   \n",
       "\n",
       "   Blood Pressure Diastolic       Date  \n",
       "0                        72 2024-01-31  \n",
       "1                        74 2024-02-29  \n",
       "2                        88 2024-03-31  \n",
       "3                        76 2024-04-30  \n",
       "4                        78 2024-05-31  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "np.random.seed(42) # For reproducibility\n",
    "patient_ids = np.arange(1, 11)\n",
    "ages = np.random.randint(20, 70, size=10)\n",
    "weights = np.random.uniform(55, 100, size=10)\n",
    "cholesterol_levels = np.random.randint(150, 250, size=10)\n",
    "blood_pressures_systolic = np.random.randint(110, 140, size=10)\n",
    "blood_pressures_diastolic = np.random.randint(70, 90, size=10)\n",
    "dates = pd.date_range('2024-01-01', periods=10, freq='ME')\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Patient ID': patient_ids,\n",
    "    'Age': ages,\n",
    "    'Weight': weights,\n",
    "    'Cholesterol Level': cholesterol_levels,\n",
    "    'Blood Pressure Systolic': blood_pressures_systolic,\n",
    "    'Blood Pressure Diastolic': blood_pressures_diastolic,\n",
    "    'Date': dates\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7914751",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 1: Calculate the average weight of the patient population.\n",
    "Use NumPy to compute the mean of the Weight column, providing insights into the general health status of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2df7a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(77.11366460070388)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating average weight\n",
    "average_weight = np.mean(weights)\n",
    "average_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3b745",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 2: Determine the median cholesterol level.\n",
    "Calculate the median of the Cholesterol Level column to find the middle value of cholesterol levels, helping to understand the distribution of cholesterol levels among patients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e25a8d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(208.5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining median cholesterol level\n",
    "median_cholesterol = np.median(cholesterol_levels)\n",
    "median_cholesterol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5db3a",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 3: Identify the range of blood pressure readings in the dataset.\n",
    "Utilize NumPy to find the maximum and minimum values in the Blood Pressure readings, giving an idea of the variation in blood pressure across the patient population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f528f486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(18), np.int64(16))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting systolic and diastolic blood pressures for range calculation\n",
    "systolic_range = blood_pressures_systolic.max() - blood_pressures_systolic.min()\n",
    "diastolic_range = blood_pressures_diastolic.max() - blood_pressures_diastolic.min()\n",
    "systolic_range, diastolic_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5147132",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 4: Evaluate the standard deviation of ages.\n",
    "Calculate the standard deviation of the Age column using NumPy to assess the age diversity of the patient population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd05075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(11.713667231059622)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating standard deviation of ages\n",
    "std_dev_ages = np.std(ages)\n",
    "std_dev_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204dd14d",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 5: How Many Patients Fall into Each Category of Blood Pressure Status?\n",
    "\n",
    "Classify patients into categories based on their systolic and diastolic blood pressure readings to assess the prevalence of normal blood pressure, elevated blood pressure, and different stages of hypertension within the patient population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c90d1408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blood Pressure Category\n",
       "Hypertension Stage 1    7\n",
       "Elevated                3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_blood_pressure(row):\n",
    "    if row['Blood Pressure Systolic'] < 120 and row['Blood Pressure Diastolic'] < 80:\n",
    "        return 'Normal'\n",
    "    elif 120 <= row['Blood Pressure Systolic'] <= 129 and row['Blood Pressure Diastolic'] < 80:\n",
    "        return 'Elevated'\n",
    "    elif 130 <= row['Blood Pressure Systolic'] <= 139 or 80 <= row['Blood Pressure Diastolic'] <= 89:\n",
    "        return 'Hypertension Stage 1'\n",
    "    elif row['Blood Pressure Systolic'] >= 140 or row['Blood Pressure Diastolic'] >= 90:\n",
    "        return 'Hypertension Stage 2'\n",
    "    else:\n",
    "        return 'Hypertensive Crisis'\n",
    "\n",
    "# Apply the function to categorize blood pressure for each patient\n",
    "df['Blood Pressure Category'] = df.apply(categorize_blood_pressure, axis=1)\n",
    "\n",
    "# Count the number of patients in each blood pressure category\n",
    "blood_pressure_counts = df['Blood Pressure Category'].value_counts()\n",
    "blood_pressure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439d229",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 6: What is the Average Cholesterol Level for Each Decade of Age?\n",
    "\n",
    "Calculate the average cholesterol level, grouping patients by their age in decades (20s, 30s, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c43c970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age Decade\n",
       "20    240.0\n",
       "30    236.0\n",
       "40    196.0\n",
       "50    199.0\n",
       "60    198.0\n",
       "Name: Cholesterol Level, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column for age decade\n",
    "df['Age Decade'] = df['Age'] // 10 * 10\n",
    "\n",
    "# Calculate the average cholesterol level for each age decade\n",
    "average_cholesterol_by_decade = df.groupby('Age Decade')['Cholesterol Level'].mean()\n",
    "average_cholesterol_by_decade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f2220",
   "metadata": {},
   "source": [
    "### 💡📝 Exercise 7:  How Many Patients Have Cholesterol Levels Above the Median?\n",
    "\n",
    "Determine the number of patients whose cholesterol levels are above the median value, providing a simple measure of how cholesterol levels are distributed across the patient population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f44fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many patients have cholesterol levels above this median\n",
    "patients_above_median_cholesterol = df[df['Cholesterol Level'] > median_cholesterol].shape[0]\n",
    "patients_above_median_cholesterol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c631d4",
   "metadata": {},
   "source": [
    "### 💡📝 TO-DO Exercise 8:  Update the Dataset to Include BMI (Body Mass Index)\n",
    "Objective: Enhance the dataset with a new column for BMI, calculated from each patient's weight (in kg) and an assumed average height (since height is not provided in the dataset, you could assume a fixed value for simplicity, such as 1.75 meters for all patients).\n",
    "\n",
    "Approach:\n",
    "\n",
    "* Calculate BMI using the formula below.\n",
    "* Add the BMI calculations as a new column in the DataFrame.\n",
    "* Analyze the distribution of BMI across the dataset to identify how many patients might be classified as underweight, normal weight, overweight, or obese based on standard BMI categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5bb3bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.591836734693878"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height_m = 1.75  # Assuming an average height of 1.75 meters for all patients\n",
    "weight = 60\n",
    "bmi = weight / height_m**2\n",
    "bmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2d651",
   "metadata": {},
   "source": [
    "### 💡📝 TO-DO Exercise 9:  Standardize the Weight Column Using NumPy\n",
    "\n",
    "Objective: Standardize the values in the Weight column to have a mean of 0 and a standard deviation of 1. This process will allow for the comparison of weights in a way that is independent of the original unit scale, useful in many statistical analyses and machine learning algorithms.\n",
    "\n",
    "Approach:\n",
    "* Extract the Weight column into a NumPy array.\n",
    "* Subtract the mean of the array from each element and then divide by the standard deviation of the array.\n",
    "* Optionally, update the DataFrame with the standardized weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec283b7c",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Python Data Science Handbook [https://jakevdp.github.io/PythonDataScienceHandbook/]\n",
    "2. Python for Data Analysis [https://bedford-computing.co.uk/learning/wp-content/uploads/2015/10/Python-for-Data-Analysis.pdf] — Written by the creator of Pandas, you can go through this book for in-depth examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d0075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
